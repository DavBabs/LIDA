{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01af8edf-31e8-47a3-9aca-573547b2f86b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 28 (chamber.py, line 29)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mD:\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[1], line 1\u001b[0m\n    from lidaEnvironment import CompostingEnv\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mD:\\LIDA-2024Ver\\LidaCode\\lidaEnvironment.py:7\u001b[1;36m\n\u001b[1;33m    from chamber import Chamber\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mD:\\LIDA-2024Ver\\LidaCode\\chamber.py:29\u001b[1;36m\u001b[0m\n\u001b[1;33m    return np.round(value, 2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 28\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle\n",
    "def test_compost_cycle():\n",
    "    # Predefined sequence of actions (order: paddle, air pump, lid, duration)\n",
    "    actions = [\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all on\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 0, \"lid\": 1, \"duration\": 200},  # Middle stage, air pump off\n",
    "        {\"paddle\": (0, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 0, \"duration\": 150}   # Final stage, paddle and lid off\n",
    "    ]\n",
    "\n",
    "    # Execute each action in the sequence\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Set different action for curing chamber if needed\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response\n",
    "def test_environment_response():\n",
    "    # Set random environmental changes for temperature, CO2, and moisture\n",
    "    random_adjustments = [\n",
    "        {\"temperature\": random.uniform(-1, 1), \"co2\": random.uniform(-0.5, 0.5), \"moisture\": random.uniform(-0.2, 0.2)}\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "    # Apply each environmental adjustment\n",
    "    for i, adjustment in enumerate(random_adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        print(f\"Post-adjustment Observation: {obs}\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7ca36f-0541-4967-aa08-d45826939e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 0), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 0), 'air_pump': 0, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=100.0, moisture=31.0, oxygen=45.0, co2=29.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=41.0, oxygen=48.0, co2=30.0, methane=-8.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([100., 100., 100., 100.]), 'moisture': array([30., 32.]), 'oxygen': array([45.]), 'co2': array([29.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([100., 100.]), 'moisture': array([40., 42.]), 'oxygen': array([48.]), 'co2': array([30.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: False\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (0, 1), 'air_pump': 1, 'lid': 0, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=31.0, oxygen=90.0, co2=29.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([30., 32.]), 'oxygen': array([90.]), 'co2': array([29.]), 'methane': array([-24.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([40., 42.]), 'oxygen': array([93.]), 'co2': array([30.]), 'methane': array([-23.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': -0.3056208194743957, 'co2': 0.24356315256880734, 'moisture': -0.1859095357936835}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.81, oxygen=100.0, co2=29.24, methane=-114.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.81, 31.81]), 'oxygen': array([100.]), 'co2': array([29.24]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.81, 31.81]), 'oxygen': array([100.]), 'co2': array([29.24]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.10689008650783904, 'co2': 0.4220015432214138, 'moisture': -0.07956609536346743}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.73, oxygen=100.0, co2=29.66, methane=-204.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.73, 31.73]), 'oxygen': array([100.]), 'co2': array([29.66]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.73, 31.73]), 'oxygen': array([100.]), 'co2': array([29.66]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': -0.36835054356319463, 'co2': 0.44607911074897144, 'moisture': -0.104472387431951}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.62, oxygen=100.0, co2=30.1, methane=-294.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.62, 31.62]), 'oxygen': array([100.]), 'co2': array([30.1]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.62, 31.62]), 'oxygen': array([100.]), 'co2': array([30.1]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': -0.7059516753754913, 'co2': 0.030502024563659802, 'moisture': 0.19031092814037964}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.81, oxygen=100.0, co2=30.13, methane=-384.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.81, 31.81]), 'oxygen': array([100.]), 'co2': array([30.13]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.81, 31.81]), 'oxygen': array([100.]), 'co2': array([30.13]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.9341838742536963, 'co2': 0.47648194931025933, 'moisture': -0.01940745703924765}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.79, oxygen=100.0, co2=30.6, methane=-474.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.79, 31.79]), 'oxygen': array([100.]), 'co2': array([30.6]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.79, 31.79]), 'oxygen': array([100.]), 'co2': array([30.6]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle\n",
    "def test_compost_cycle():\n",
    "    # Predefined sequence of actions (order: paddle, air pump, lid, duration)\n",
    "    actions = [\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all on\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 0, \"lid\": 1, \"duration\": 200},  # Middle stage, air pump off\n",
    "        {\"paddle\": (0, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 0, \"duration\": 150}   # Final stage, paddle and lid off\n",
    "    ]\n",
    "\n",
    "    # Execute each action in the sequence\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Set different action for curing chamber if needed\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response\n",
    "def test_environment_response():\n",
    "    # Set random environmental changes for temperature, CO2, and moisture\n",
    "    random_adjustments = [\n",
    "        {\"temperature\": random.uniform(-1, 1), \"co2\": random.uniform(-0.5, 0.5), \"moisture\": random.uniform(-0.2, 0.2)}\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "    # Apply each environmental adjustment\n",
    "    for i, adjustment in enumerate(random_adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        print(f\"Post-adjustment Observation: {obs}\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fdc093-6b51-4960-a9a3-9d419fc7ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 0), 'air_pump': 0, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=100.0, moisture=31.0, oxygen=45.0, co2=29.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=41.0, oxygen=48.0, co2=30.0, methane=-8.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([100., 100., 100., 100.]), 'moisture': array([30., 32.]), 'oxygen': array([45.]), 'co2': array([29.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([100., 100.]), 'moisture': array([40., 42.]), 'oxygen': array([48.]), 'co2': array([30.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: False\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (0, 1), 'air_pump': 1, 'lid': 0, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=31.0, oxygen=90.0, co2=29.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([30., 32.]), 'oxygen': array([90.]), 'co2': array([29.]), 'methane': array([-24.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([40., 42.]), 'oxygen': array([93.]), 'co2': array([30.]), 'methane': array([-23.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.0038546119762967734, 'co2': -0.4202957714152852, 'moisture': 0.1252312192544076}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.119999999999997, oxygen=100.0, co2=28.57, methane=-114.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.12, 32.12]), 'oxygen': array([100.]), 'co2': array([28.57]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.12, 32.12]), 'oxygen': array([100.]), 'co2': array([28.57]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.9917298029397175, 'co2': -0.04300041361396567, 'moisture': -0.14369850695566752}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.97, oxygen=100.0, co2=28.52, methane=-204.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.97, 31.97]), 'oxygen': array([100.]), 'co2': array([28.52]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.97, 31.97]), 'oxygen': array([100.]), 'co2': array([28.52]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': -0.5153056398478584, 'co2': -0.43182335560768037, 'moisture': 0.01426436470757525}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.98, oxygen=100.0, co2=28.08, methane=-294.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.98, 31.98]), 'oxygen': array([100.]), 'co2': array([28.08]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.98, 31.98]), 'oxygen': array([100.]), 'co2': array([28.08]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.7118345424927759, 'co2': -0.3649933756962066, 'moisture': 0.1465445093727763}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.119999999999997, oxygen=100.0, co2=27.71, methane=-384.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.12, 32.12]), 'oxygen': array([100.]), 'co2': array([27.71]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.12, 32.12]), 'oxygen': array([100.]), 'co2': array([27.71]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.7196243584926563, 'co2': 0.3232148439843222, 'moisture': -0.15450704384431618}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=30.96, oxygen=100.0, co2=28.03, methane=-474.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.96, 31.96]), 'oxygen': array([100.]), 'co2': array([28.03]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([29.96, 31.96]), 'oxygen': array([100.]), 'co2': array([28.03]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle\n",
    "def test_compost_cycle():\n",
    "    # Predefined sequence of actions (order: paddle, air pump, lid, duration)\n",
    "    actions = [\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all on\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 0, \"lid\": 1, \"duration\": 200},  # Middle stage, air pump off\n",
    "        {\"paddle\": (0, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 0, \"duration\": 150}   # Final stage, paddle and lid off\n",
    "    ]\n",
    "\n",
    "    # Execute each action in the sequence\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Set different action for curing chamber if needed\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response\n",
    "def test_environment_response():\n",
    "    # Set random environmental changes for temperature, CO2, and moisture\n",
    "    random_adjustments = [\n",
    "        {\"temperature\": random.uniform(-1, 1), \"co2\": random.uniform(-0.5, 0.5), \"moisture\": random.uniform(-0.2, 0.2)}\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "    # Apply each environmental adjustment\n",
    "    for i, adjustment in enumerate(random_adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        print(f\"Post-adjustment Observation: {obs}\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3123b8ad-f959-495d-bcd1-2fe80d7fe514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 0, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=100.0, moisture=31.0, oxygen=45.0, co2=29.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=41.0, oxygen=48.0, co2=30.0, methane=-8.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([100., 100., 100., 100.]), 'moisture': array([30., 32.]), 'oxygen': array([45.]), 'co2': array([29.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([100., 100.]), 'moisture': array([40., 42.]), 'oxygen': array([48.]), 'co2': array([30.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: False\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (0, 0), 'air_pump': 1, 'lid': 0, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=31.0, oxygen=90.0, co2=29.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([30., 32.]), 'oxygen': array([90.]), 'co2': array([29.]), 'methane': array([-24.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([40., 42.]), 'oxygen': array([93.]), 'co2': array([30.]), 'methane': array([-23.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.22663724279551323, 'co2': -0.27369270217935215, 'moisture': 0.19999923629269933}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.189999999999998, oxygen=100.0, co2=28.72, methane=-114.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.19, 32.19]), 'oxygen': array([100.]), 'co2': array([28.72]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.19, 32.19]), 'oxygen': array([100.]), 'co2': array([28.72]), 'methane': array([-114.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-113.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': 0.7561457762436457, 'co2': -0.31850527614837987, 'moisture': -0.044397580081137006}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.14, oxygen=100.0, co2=28.4, methane=-204.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.14, 32.14]), 'oxygen': array([100.]), 'co2': array([28.4]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.14, 32.14]), 'oxygen': array([100.]), 'co2': array([28.4]), 'methane': array([-204.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-203.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': -0.1385433882908722, 'co2': -0.3848966609135266, 'moisture': 0.0726295320761286}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.21, oxygen=100.0, co2=28.01, methane=-294.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.21, 32.21]), 'oxygen': array([100.]), 'co2': array([28.01]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.21, 32.21]), 'oxygen': array([100.]), 'co2': array([28.01]), 'methane': array([-294.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-293.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': -0.8414433042469331, 'co2': -0.1375813707985044, 'moisture': 0.11143777608182032}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.32, oxygen=100.0, co2=27.87, methane=-384.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.32, 32.32]), 'oxygen': array([100.]), 'co2': array([27.87]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.32, 32.32]), 'oxygen': array([100.]), 'co2': array([27.87]), 'methane': array([-384.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-383.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.5011265667334621, 'co2': -0.3728437457860132, 'moisture': 0.07570927738845812}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.39, oxygen=100.0, co2=27.49, methane=-474.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.39, 32.39]), 'oxygen': array([100.]), 'co2': array([27.49]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30.39, 32.39]), 'oxygen': array([100.]), 'co2': array([27.49]), 'methane': array([-474.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-473.]), 'isEmpty': True}}\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle\n",
    "def test_compost_cycle():\n",
    "    # Predefined sequence of actions (order: paddle, air pump, lid, duration)\n",
    "    actions = [\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all on\n",
    "        {\"paddle\": (1, random.choice([0, 1])), \"air_pump\": 0, \"lid\": 1, \"duration\": 200},  # Middle stage, air pump off\n",
    "        {\"paddle\": (0, random.choice([0, 1])), \"air_pump\": 1, \"lid\": 0, \"duration\": 150}   # Final stage, paddle and lid off\n",
    "    ]\n",
    "\n",
    "    # Execute each action in the sequence\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Set different action for curing chamber if needed\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response\n",
    "def test_environment_response():\n",
    "    # Set random environmental changes for temperature, CO2, and moisture\n",
    "    random_adjustments = [\n",
    "        {\"temperature\": random.uniform(-1, 1), \"co2\": random.uniform(-0.5, 0.5), \"moisture\": random.uniform(-0.2, 0.2)}\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "    # Apply each environmental adjustment\n",
    "    for i, adjustment in enumerate(random_adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        print(f\"Post-adjustment Observation: {obs}\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8708ce1-5156-4a46-9a29-9b6b14ad0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to simulate a single step with a given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Format reward to two decimal places\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle to increase rewards\n",
    "def test_compost_cycle():\n",
    "    # Actions are chosen to ideally align with optimal conditions for reward increase\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Optimized initial stage\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200},  # Continue optimal action\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150}   # Maintaining optimal actions\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Setting same action for curing chamber\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "        if reward >= 0.8:  # Arbitrary threshold for high reward\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Deliberate environmental adjustments for better rewards\n",
    "def test_environment_response():\n",
    "    # Adjustments are made to nudge values closer to optimal ranges\n",
    "    adjustments = [\n",
    "        {\"temperature\": 5, \"co2\": 3, \"moisture\": -1},  # Target specific changes\n",
    "        {\"temperature\": -3, \"co2\": 0.2, \"moisture\": 1},\n",
    "        {\"temperature\": 1, \"co2\": -0.1, \"moisture\": 2},\n",
    "        {\"temperature\": 4, \"co2\": 0.5, \"moisture\": 1},\n",
    "        {\"temperature\": 3, \"co2\": -0.2, \"moisture\": -1}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0693a573-4911-4b5e-9e5f-6798ac0c0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.0, oxygen=100.0, co2=29.0, methane=-29.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30., 32.]), 'oxygen': array([100.]), 'co2': array([29.]), 'methane': array([-29.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-28.]), 'isEmpty': True}}\n",
      "Reward: 35\n",
      "Done: True\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30., 32.]), 'oxygen': array([100.]), 'co2': array([29.]), 'methane': array([-29.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-28.]), 'isEmpty': True}}\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([15., 17.]), 'oxygen': array([100.]), 'co2': array([41.]), 'methane': array([-44.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([25., 27.]), 'oxygen': array([100.]), 'co2': array([42.]), 'methane': array([-43.]), 'isEmpty': True}}\n",
      "Reward: 10\n",
      "Done: True\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([15., 17.]), 'oxygen': array([100.]), 'co2': array([41.]), 'methane': array([-44.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([25., 27.]), 'oxygen': array([100.]), 'co2': array([42.]), 'methane': array([-43.]), 'isEmpty': True}}\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': -0.24729810829530896, 'co2': 0.4368578844325648, 'moisture': 0.008292433267174604}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-74.0, oxygen=100.0, co2=113.43, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-75., -73.]), 'oxygen': array([100.]), 'co2': array([113.43]), 'methane': array([-134.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-65., -63.]), 'oxygen': array([100.]), 'co2': array([114.]), 'methane': array([-133.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-75., -73.]), 'oxygen': array([100.]), 'co2': array([113.43]), 'methane': array([-134.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-65., -63.]), 'oxygen': array([100.]), 'co2': array([114.]), 'methane': array([-133.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': 0.8279699930636577, 'co2': -0.4852265270323627, 'moisture': -0.1707646174556715}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=184.94, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([184.94]), 'methane': array([-224.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([186.]), 'methane': array([-223.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([184.94]), 'methane': array([-224.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([186.]), 'methane': array([-223.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': -0.4888614280649264, 'co2': -0.4731806117075975, 'moisture': -0.19170851655567767}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=256.46, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([256.46]), 'methane': array([-314.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([258.]), 'methane': array([-313.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([256.46]), 'methane': array([-314.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([258.]), 'methane': array([-313.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': -0.3876168491099068, 'co2': 0.27211256816207907, 'moisture': 0.10753637921665138}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=328.73, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([328.73]), 'methane': array([-404.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([330.]), 'methane': array([-403.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([328.73]), 'methane': array([-404.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([330.]), 'methane': array([-403.]), 'isEmpty': True}}\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.2493167993809089, 'co2': -0.043803084408964965, 'moisture': -0.19093939175167762}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=400.68, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([400.68]), 'methane': array([-494.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([402.]), 'methane': array([-493.]), 'isEmpty': True}}\n",
      "Reward: 0\n",
      "Done: True\n",
      "Post-adjustment Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([400.68]), 'methane': array([-494.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([402.]), 'methane': array([-493.]), 'isEmpty': True}}\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with formatted output and optimized actions\n",
    "def test_compost_cycle():\n",
    "    # Actions are chosen to align with optimal conditions for reward increase\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Optimized initial stage\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200},  # Continue optimal action\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150}   # Maintaining optimal actions\n",
    "    ]\n",
    "\n",
    "    # Execute each action in the sequence\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action  # Setting same action for curing chamber\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "        \n",
    "        # Format the output with dividers for clarity\n",
    "        print(f\"Observation: {obs}\")\n",
    "        print(f\"Reward: {reward:.2f}\")  # Print reward with two decimal precision\n",
    "        print(f\"Done: {done}\\n{'='*30}\")  # Print divider for each step\n",
    "\n",
    "        # Extra check for high reward notification\n",
    "        if reward >= 0.8:  # Threshold for a high reward\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response\n",
    "def test_environment_response():\n",
    "    # Set random environmental changes for temperature, CO2, and moisture\n",
    "    random_adjustments = [\n",
    "        {\"temperature\": random.uniform(-1, 1), \"co2\": random.uniform(-0.5, 0.5), \"moisture\": random.uniform(-0.2, 0.2)}\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "    # Apply each environmental adjustment\n",
    "    for i, adjustment in enumerate(random_adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        print(f\"Post-adjustment Observation: {obs}\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e2d8dc9-15f2-4b0b-8a78-19541737ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=31.0, oxygen=100.0, co2=29.0, methane=-29.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([30., 32.]), 'oxygen': array([100.]), 'co2': array([29.]), 'methane': array([-29.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([40., 42.]), 'oxygen': array([100.]), 'co2': array([30.]), 'methane': array([-28.]), 'isEmpty': True}}\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([15., 17.]), 'oxygen': array([100.]), 'co2': array([41.]), 'methane': array([-44.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([25., 27.]), 'oxygen': array([100.]), 'co2': array([42.]), 'methane': array([-43.]), 'isEmpty': True}}\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.5, 'co2': 0.3, 'moisture': -0.1}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-74.10499999999999, oxygen=100.0, co2=113.3, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-75.1 , -73.11]), 'oxygen': array([100.]), 'co2': array([113.3]), 'methane': array([-134.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-65., -63.]), 'oxygen': array([100.]), 'co2': array([114.]), 'methane': array([-133.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.3, 'co2': 0.2, 'moisture': 0.1}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=185.5, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([185.5]), 'methane': array([-224.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([186.]), 'methane': array([-223.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 0.1, 'co2': -0.1, 'moisture': 0.2}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=257.39, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([257.39]), 'methane': array([-314.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([258.]), 'methane': array([-313.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.4, 'co2': 0.5, 'moisture': 0.1}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=329.89, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([329.89]), 'methane': array([-404.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([330.]), 'methane': array([-403.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.3, 'co2': -0.2, 'moisture': -0.1}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=401.69, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([401.69]), 'methane': array([-494.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([402.]), 'methane': array([-493.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all optimized\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200},  # Continuing with optimal action\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150}   # Final stage, maintaining settings\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        # Apply the action to both active and curing chambers\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "        \n",
    "        # Check if reward is high enough to confirm optimal action\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Simulate environmental response to specific adjustments\n",
    "def test_environment_response():\n",
    "    # Specific environmental adjustments to improve reward\n",
    "    adjustments = [\n",
    "        {\"temperature\": 0.5, \"co2\": 0.3, \"moisture\": -0.1},\n",
    "        {\"temperature\": -0.3, \"co2\": 0.2, \"moisture\": 0.1},\n",
    "        {\"temperature\": 0.1, \"co2\": -0.1, \"moisture\": 0.2},\n",
    "        {\"temperature\": 0.4, \"co2\": 0.5, \"moisture\": 0.1},\n",
    "        {\"temperature\": 0.3, \"co2\": -0.2, \"moisture\": -0.1}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06633145-7564-4b92-9022-1987f0b502bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-20., -20., -20., -20.]), 'moisture': array([50., 52.]), 'oxygen': array([45.]), 'co2': array([13.]), 'methane': array([-9.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-20., -20.]), 'moisture': array([60., 62.]), 'oxygen': array([48.]), 'co2': array([14.]), 'methane': array([-8.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=36.0, oxygen=90.0, co2=25.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-80., -80., -80., -80.]), 'moisture': array([35., 37.]), 'oxygen': array([90.]), 'co2': array([25.]), 'methane': array([-24.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-80., -80.]), 'moisture': array([45., 47.]), 'oxygen': array([93.]), 'co2': array([26.]), 'methane': array([-23.]), 'isEmpty': True}}\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([15., 17.]), 'oxygen': array([100.]), 'co2': array([41.]), 'methane': array([-44.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([25., 27.]), 'oxygen': array([100.]), 'co2': array([42.]), 'methane': array([-43.]), 'isEmpty': True}}\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.5432246144568058, 'co2': 0.34805622057360597, 'moisture': -0.11476369910513098}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-74.12, oxygen=100.0, co2=113.34, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-75.12, -73.12]), 'oxygen': array([100.]), 'co2': array([113.34]), 'methane': array([-134.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-65., -63.]), 'oxygen': array([100.]), 'co2': array([114.]), 'methane': array([-133.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.26822840471481924, 'co2': 0.2108946306511194, 'moisture': 0.06485241330002124}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=185.55, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([185.55]), 'methane': array([-224.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([186.]), 'methane': array([-223.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 0.06706485079269045, 'co2': -0.10465314582984786, 'moisture': 0.2023729957190573}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=257.44, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([257.44]), 'methane': array([-314.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([258.]), 'methane': array([-313.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.3093879593964746, 'co2': 0.5321441828176974, 'moisture': 0.06154628860968489}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=329.97, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([329.97]), 'methane': array([-404.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([330.]), 'methane': array([-403.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.2473869529517479, 'co2': -0.21688933306897165, 'moisture': -0.12569175534678007}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=401.75, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation: {'active_chamber': {'temperature': array([-100., -100., -100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([401.75]), 'methane': array([-494.]), 'isEmpty': False}, 'curing_chamber': {'temperature': array([-100., -100.]), 'moisture': array([-100., -100.]), 'oxygen': array([100.]), 'co2': array([402.]), 'methane': array([-493.]), 'isEmpty': True}}\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all optimized\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},  # Maintain optimal conditions with gradual change\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}   # Final stage, maintaining settings\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments\n",
    "def test_environment_response():\n",
    "    # Gradual changes with added noise for more realistic values\n",
    "    adjustments = [\n",
    "        {\"temperature\": 0.5 + random.uniform(-0.1, 0.1), \"co2\": 0.3 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": -0.3 + random.uniform(-0.1, 0.1), \"co2\": 0.2 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.1 + random.uniform(-0.1, 0.1), \"co2\": -0.1 + random.uniform(-0.05, 0.05), \"moisture\": 0.2 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.4 + random.uniform(-0.1, 0.1), \"co2\": 0.5 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.3 + random.uniform(-0.1, 0.1), \"co2\": -0.2 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        env.active_chamber.update_temperature(adjustment[\"temperature\"])\n",
    "        env.active_chamber.update_co2(adjustment[\"co2\"])\n",
    "        env.active_chamber.update_moisture(adjustment[\"moisture\"])\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b5c9b4-cbe1-4805-9802-196c2e6edca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-20.00', '-20.00', '-20.00', '-20.00']\n",
      "    moisture: ['50.00', '52.00']\n",
      "    oxygen: ['45.00']\n",
      "    co2: ['13.00']\n",
      "    methane: ['-9.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-20.00', '-20.00']\n",
      "    moisture: ['60.00', '62.00']\n",
      "    oxygen: ['48.00']\n",
      "    co2: ['14.00']\n",
      "    methane: ['-8.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=36.0, oxygen=90.0, co2=25.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-80.00', '-80.00', '-80.00', '-80.00']\n",
      "    moisture: ['35.00', '37.00']\n",
      "    oxygen: ['90.00']\n",
      "    co2: ['25.00']\n",
      "    methane: ['-24.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-80.00', '-80.00']\n",
      "    moisture: ['45.00', '47.00']\n",
      "    oxygen: ['93.00']\n",
      "    co2: ['26.00']\n",
      "    methane: ['-23.00']\n",
      "    isEmpty: True\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['15.00', '17.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['41.00']\n",
      "    methane: ['-44.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['25.00', '27.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['42.00']\n",
      "    methane: ['-43.00']\n",
      "    isEmpty: True\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.5573010380219288, 'co2': 0.33796162066674396, 'moisture': -0.12783343893443458}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-74.11, oxygen=100.0, co2=113.3, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-75.11', '-73.11']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['113.30']\n",
      "    methane: ['-134.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-65.16', '-63.16']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['114.27']\n",
      "    methane: ['-133.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.33523283447592594, 'co2': 0.21170613758412984, 'moisture': 0.05648152129816079}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=185.5, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['185.50']\n",
      "    methane: ['-224.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['186.51']\n",
      "    methane: ['-223.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 0.17704360348641077, 'co2': -0.12624845300512266, 'moisture': 0.1560963732581004}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=257.45, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['257.45']\n",
      "    methane: ['-314.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['258.39']\n",
      "    methane: ['-313.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.3727029247704232, 'co2': 0.4528528359047397, 'moisture': 0.10061842952687677}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=329.81, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['329.81']\n",
      "    methane: ['-404.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['330.80']\n",
      "    methane: ['-403.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.20997834828927298, 'co2': -0.1664739276216742, 'moisture': -0.12353507541357457}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=401.63, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['401.63']\n",
      "    methane: ['-494.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['402.59']\n",
      "    methane: ['-493.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Print observation with more realistic formatting\n",
    "    print(\"Observation:\")\n",
    "    for chamber, readings in obs.items():\n",
    "        print(f\"  {chamber.capitalize()}:\")\n",
    "        for sensor, values in readings.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                values = [f\"{v:.2f}\" for v in values]  # Display with 2 decimal places\n",
    "            print(f\"    {sensor}: {values}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    \n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},  # Initial stage, all optimized\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},  # Maintain optimal conditions with gradual change\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}   # Final stage, maintaining settings\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments with variance\n",
    "def test_environment_response():\n",
    "    # Gradual changes with added noise for more realistic values\n",
    "    adjustments = [\n",
    "        {\"temperature\": 0.5 + random.uniform(-0.1, 0.1), \"co2\": 0.3 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": -0.3 + random.uniform(-0.1, 0.1), \"co2\": 0.2 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.1 + random.uniform(-0.1, 0.1), \"co2\": -0.1 + random.uniform(-0.05, 0.05), \"moisture\": 0.2 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.4 + random.uniform(-0.1, 0.1), \"co2\": 0.5 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.3 + random.uniform(-0.1, 0.1), \"co2\": -0.2 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        \n",
    "        # Apply a small random variation to each sensor in the chamber for a more natural array output\n",
    "        for chamber in [env.active_chamber, env.curing_chamber]:\n",
    "            chamber.update_temperature(adjustment[\"temperature\"] + random.uniform(-0.2, 0.2))\n",
    "            chamber.update_co2(adjustment[\"co2\"] + random.uniform(-0.1, 0.1))\n",
    "            chamber.update_moisture(adjustment[\"moisture\"] + random.uniform(-0.1, 0.1))\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        \n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13480c10-a3d0-4030-910d-442cd95ce0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-20.00', '-20.00', '-20.00', '-20.00']\n",
      "    moisture: ['50.00', '52.00']\n",
      "    oxygen: ['45.00']\n",
      "    co2: ['13.00']\n",
      "    methane: ['-9.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-20.00', '-20.00']\n",
      "    moisture: ['60.00', '62.00']\n",
      "    oxygen: ['48.00']\n",
      "    co2: ['14.00']\n",
      "    methane: ['-8.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=36.0, oxygen=90.0, co2=25.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-80.00', '-80.00', '-80.00', '-80.00']\n",
      "    moisture: ['35.00', '37.00']\n",
      "    oxygen: ['90.00']\n",
      "    co2: ['25.00']\n",
      "    methane: ['-24.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-80.00', '-80.00']\n",
      "    moisture: ['45.00', '47.00']\n",
      "    oxygen: ['93.00']\n",
      "    co2: ['26.00']\n",
      "    methane: ['-23.00']\n",
      "    isEmpty: True\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['15.00', '17.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['41.00']\n",
      "    methane: ['-44.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['25.00', '27.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['42.00']\n",
      "    methane: ['-43.00']\n",
      "    isEmpty: True\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.4531858392274458, 'co2': 0.25676503972829046, 'moisture': -0.07671859707037137}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-15.66, oxygen=100.0, co2=173.0, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-16.66', '-14.66']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['173.00']\n",
      "    methane: ['-134.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-21.92', '-19.93']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['139.51']\n",
      "    methane: ['-133.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.23696207148855636, 'co2': 0.19113630661586253, 'moisture': 0.10165816183536787}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-77.0, oxygen=100.0, co2=294.75, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-78.00', '-76.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['294.75']\n",
      "    methane: ['-224.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-52.75', '-50.76']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['248.38']\n",
      "    methane: ['-223.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 0.141540472632242, 'co2': -0.079979136444153, 'moisture': 0.19007507437471438}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=401.79, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['401.79']\n",
      "    methane: ['-314.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['369.68']\n",
      "    methane: ['-313.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.3134670558849781, 'co2': 0.5192541361517065, 'moisture': 0.1453188398442825}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=500.22, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['500.22']\n",
      "    methane: ['-404.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['458.57']\n",
      "    methane: ['-403.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.37806625315435427, 'co2': -0.18570121293607092, 'moisture': -0.10928197419170932}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=620.72, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['620.72']\n",
      "    methane: ['-494.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['563.90']\n",
      "    methane: ['-493.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Print observation with more realistic formatting\n",
    "    print(\"Observation:\")\n",
    "    for chamber, readings in obs.items():\n",
    "        print(f\"  {chamber.capitalize()}:\")\n",
    "        for sensor, values in readings.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                values = [f\"{v:.2f}\" for v in values]  # Display with 2 decimal places\n",
    "            print(f\"    {sensor}: {values}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    \n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments with variance in range\n",
    "def test_environment_response():\n",
    "    # Gradual changes with controlled variance for realistic values between 15 and 60\n",
    "    adjustments = [\n",
    "        {\"temperature\": 0.5 + random.uniform(-0.1, 0.1), \"co2\": 0.3 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": -0.3 + random.uniform(-0.1, 0.1), \"co2\": 0.2 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.1 + random.uniform(-0.1, 0.1), \"co2\": -0.1 + random.uniform(-0.05, 0.05), \"moisture\": 0.2 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.4 + random.uniform(-0.1, 0.1), \"co2\": 0.5 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.3 + random.uniform(-0.1, 0.1), \"co2\": -0.2 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        \n",
    "        # Apply a controlled update for each sensor, limiting values to 15-60\n",
    "        for chamber in [env.active_chamber, env.curing_chamber]:\n",
    "            chamber.update_temperature(np.clip(adjustment[\"temperature\"] + random.uniform(15, 60), 15, 60))\n",
    "            chamber.update_co2(np.clip(adjustment[\"co2\"] + random.uniform(15, 60), 15, 60))\n",
    "            chamber.update_moisture(np.clip(adjustment[\"moisture\"] + random.uniform(15, 60), 15, 60))\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        \n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6c934c-6e38-4d90-b09d-aca92900ca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-20.00', '-20.00', '-20.00', '-20.00']\n",
      "    moisture: ['50.00', '52.00']\n",
      "    oxygen: ['45.00']\n",
      "    co2: ['13.00']\n",
      "    methane: ['-9.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-20.00', '-20.00']\n",
      "    moisture: ['60.00', '62.00']\n",
      "    oxygen: ['48.00']\n",
      "    co2: ['14.00']\n",
      "    methane: ['-8.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=36.0, oxygen=90.0, co2=25.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-80.00', '-80.00', '-80.00', '-80.00']\n",
      "    moisture: ['35.00', '37.00']\n",
      "    oxygen: ['90.00']\n",
      "    co2: ['25.00']\n",
      "    methane: ['-24.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-80.00', '-80.00']\n",
      "    moisture: ['45.00', '47.00']\n",
      "    oxygen: ['93.00']\n",
      "    co2: ['26.00']\n",
      "    methane: ['-23.00']\n",
      "    isEmpty: True\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['15.00', '17.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['41.00']\n",
      "    methane: ['-44.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['25.00', '27.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['42.00']\n",
      "    methane: ['-43.00']\n",
      "    isEmpty: True\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 0.4672053288244875, 'co2': 0.27898094884153574, 'moisture': -0.10557384904339187}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-15.989999999999998, oxygen=100.0, co2=172.64, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-16.99', '-14.99']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['172.64']\n",
      "    methane: ['-134.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-6.88', '-4.88']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['137.26']\n",
      "    methane: ['-133.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': -0.3786411306003701, 'co2': 0.16718579289272206, 'moisture': 0.06034160395260694}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-81.25, oxygen=100.0, co2=262.85, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-82.25', '-80.25']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['262.85']\n",
      "    methane: ['-224.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-58.08', '-56.08']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['231.79']\n",
      "    methane: ['-223.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 0.1912471652187578, 'co2': -0.05878148477826815, 'moisture': 0.19810974248863872}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=381.75, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['381.75']\n",
      "    methane: ['-314.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['356.82']\n",
      "    methane: ['-313.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 0.3895180076993071, 'co2': 0.509726512153266, 'moisture': 0.14956282909846202}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=512.68, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['512.68']\n",
      "    methane: ['-404.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['446.27']\n",
      "    methane: ['-403.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 0.38409832330708377, 'co2': -0.17539827152146642, 'moisture': -0.09978058344197478}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=611.57, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['611.57']\n",
      "    methane: ['-494.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['550.57']\n",
      "    methane: ['-493.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Print observation with more realistic formatting\n",
    "    print(\"Observation:\")\n",
    "    for chamber, readings in obs.items():\n",
    "        print(f\"  {chamber.capitalize()}:\")\n",
    "        for sensor, values in readings.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                values = [f\"{v:.2f}\" for v in values]  # Display with 2 decimal places\n",
    "            print(f\"    {sensor}: {values}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    \n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments with variance in range\n",
    "def test_environment_response():\n",
    "    # Gradual changes with controlled variance for realistic values between 15 and 60\n",
    "    adjustments = [\n",
    "        {\"temperature\": 0.5 + random.uniform(-0.1, 0.1), \"co2\": 0.3 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": -0.3 + random.uniform(-0.1, 0.1), \"co2\": 0.2 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.1 + random.uniform(-0.1, 0.1), \"co2\": -0.1 + random.uniform(-0.05, 0.05), \"moisture\": 0.2 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.4 + random.uniform(-0.1, 0.1), \"co2\": 0.5 + random.uniform(-0.05, 0.05), \"moisture\": 0.1 + random.uniform(-0.05, 0.05)},\n",
    "        {\"temperature\": 0.3 + random.uniform(-0.1, 0.1), \"co2\": -0.2 + random.uniform(-0.05, 0.05), \"moisture\": -0.1 + random.uniform(-0.05, 0.05)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        \n",
    "        # Apply a controlled update for each sensor, limiting values to 15-60\n",
    "        for chamber in [env.active_chamber, env.curing_chamber]:\n",
    "            chamber.update_temperature(np.clip(adjustment[\"temperature\"] + random.uniform(15, 60), 15, 60))\n",
    "            chamber.update_co2(np.clip(adjustment[\"co2\"] + random.uniform(15, 60), 15, 60))\n",
    "            chamber.update_moisture(np.clip(adjustment[\"moisture\"] + random.uniform(15, 60), 15, 60))\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        \n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c0c3446-d772-4bcf-8af6-651fcf72ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Compost Cycle\n",
      "\n",
      "Running Step 1 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 100}\n",
      "Checking extreme values for chamber: temp=-20.0, moisture=51.0, oxygen=45.0, co2=13.0, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-20.00', '-20.00', '-20.00', '-20.00']\n",
      "    moisture: ['50.00', '52.00']\n",
      "    oxygen: ['45.00']\n",
      "    co2: ['13.00']\n",
      "    methane: ['-9.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-20.00', '-20.00']\n",
      "    moisture: ['60.00', '62.00']\n",
      "    oxygen: ['48.00']\n",
      "    co2: ['14.00']\n",
      "    methane: ['-8.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Running Step 2 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 150}\n",
      "Checking extreme values for chamber: temp=-80.0, moisture=36.0, oxygen=90.0, co2=25.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-80.00', '-80.00', '-80.00', '-80.00']\n",
      "    moisture: ['35.00', '37.00']\n",
      "    oxygen: ['90.00']\n",
      "    co2: ['25.00']\n",
      "    methane: ['-24.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-80.00', '-80.00']\n",
      "    moisture: ['45.00', '47.00']\n",
      "    oxygen: ['93.00']\n",
      "    co2: ['26.00']\n",
      "    methane: ['-23.00']\n",
      "    isEmpty: True\n",
      "Reward: 35.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Running Step 3 with Action: {'paddle': (1, 1), 'air_pump': 1, 'lid': 1, 'duration': 200}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=16.0, oxygen=100.0, co2=41.0, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['15.00', '17.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['41.00']\n",
      "    methane: ['-44.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['25.00', '27.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['42.00']\n",
      "    methane: ['-43.00']\n",
      "    isEmpty: True\n",
      "Reward: 10.00\n",
      "Done: True\n",
      "==============================\n",
      "High reward achieved, actions are aligned with optimal conditions!\n",
      "\n",
      "Testing Environment Response\n",
      "\n",
      "Environment Adjustment Step 1: {'temperature': 5.185224186412368, 'co2': 44.27370142197576, 'moisture': 13.784107349686836}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-59.0, oxygen=100.0, co2=157.45, methane=-134.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-60.00', '-58.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['157.45']\n",
      "    methane: ['-134.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-50.00', '-48.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['157.87']\n",
      "    methane: ['-133.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 2: {'temperature': 10.327716177028465, 'co2': 51.99873246866428, 'moisture': 15.287303084357372}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=282.32, methane=-224.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['282.32']\n",
      "    methane: ['-224.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['282.34']\n",
      "    methane: ['-223.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 3: {'temperature': 6.321910798195494, 'co2': 5.046031014086196, 'moisture': 12.645450173646061}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=369.32, methane=-314.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['369.32']\n",
      "    methane: ['-314.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['369.33']\n",
      "    methane: ['-313.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 4: {'temperature': 49.95453580832305, 'co2': 8.871890077986105, 'moisture': 34.89711220130952}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=456.32, methane=-404.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['456.32']\n",
      "    methane: ['-404.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['456.33']\n",
      "    methane: ['-403.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n",
      "\n",
      "Environment Adjustment Step 5: {'temperature': 34.008596343895476, 'co2': 9.888268888935347, 'moisture': 39.55653396159725}\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=-100.0, oxygen=100.0, co2=543.31, methane=-494.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Observation:\n",
      "  Active_chamber:\n",
      "    temperature: ['-100.00', '-100.00', '-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['543.31']\n",
      "    methane: ['-494.00']\n",
      "    isEmpty: False\n",
      "  Curing_chamber:\n",
      "    temperature: ['-100.00', '-100.00']\n",
      "    moisture: ['-100.00', '-100.00']\n",
      "    oxygen: ['100.00']\n",
      "    co2: ['543.32']\n",
      "    methane: ['-493.00']\n",
      "    isEmpty: True\n",
      "Reward: 0.00\n",
      "Done: True\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Print observation with more realistic formatting\n",
    "    print(\"Observation:\")\n",
    "    for chamber, readings in obs.items():\n",
    "        print(f\"  {chamber.capitalize()}:\")\n",
    "        for sensor, values in readings.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                values = [f\"{v:.2f}\" for v in values]  # Display with 2 decimal places\n",
    "            print(f\"    {sensor}: {values}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    \n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments with variance in range\n",
    "def test_environment_response():\n",
    "    # Gradual changes with controlled variance for realistic values between 15 and 60\n",
    "    adjustments = [\n",
    "        {\"temperature\": random.uniform(1, 9), \"co2\": random.uniform(15, 60), \"moisture\": random.uniform(9, 14)},\n",
    "        {\"temperature\": random.uniform(3, 17), \"co2\": random.uniform(15, 60), \"moisture\": random.uniform(9, 24)},\n",
    "        {\"temperature\": random.uniform(1, 7), \"co2\": random.uniform(5, 6), \"moisture\": random.uniform(2, 66)},\n",
    "        {\"temperature\": random.uniform(15, 60), \"co2\": random.uniform(8, 23), \"moisture\": random.uniform(15, 60)},\n",
    "        {\"temperature\": random.uniform(15, 60), \"co2\": random.uniform(9, 11), \"moisture\": random.uniform(15, 60)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        \n",
    "        # Apply controlled updates and slight random noise to each sensor, keeping values within 15-60\n",
    "        for chamber in [env.active_chamber, env.curing_chamber]:\n",
    "            chamber.update_temperature(np.clip(adjustment[\"temperature\"] + random.uniform(-1, 1), 15, 60))\n",
    "            chamber.update_co2(np.clip(adjustment[\"co2\"] + random.uniform(-1, 1), 15, 60))\n",
    "            chamber.update_moisture(np.clip(adjustment[\"moisture\"] + random.uniform(-1, 1), 15, 60))\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        \n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98dfc6-788b-4c76-b055-7e4ed28bea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidaEnvironment import CompostingEnv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the environment\n",
    "env = CompostingEnv()\n",
    "obs = env.reset()\n",
    "\n",
    "# Define a function to simulate a single step with given action\n",
    "def simulate_step(action):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Print observation with more realistic formatting\n",
    "    print(\"Observation:\")\n",
    "    for chamber, readings in obs.items():\n",
    "        print(f\"  {chamber.capitalize()}:\")\n",
    "        for sensor, values in readings.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                values = [f\"{v:.2f}\" for v in values]  # Display with 2 decimal places\n",
    "            print(f\"    {sensor}: {values}\")\n",
    "    print(f\"Reward: {reward:.2f}\")  # Display reward with two decimal points\n",
    "    print(f\"Done: {done}\")\n",
    "    print(\"=\"*30)  # Divider for readability\n",
    "    \n",
    "    return obs, reward, done\n",
    "\n",
    "# Test Scenario 1: Simulate a composting cycle with optimized actions and smooth transitions\n",
    "def test_compost_cycle():\n",
    "    # Actions designed to maximize reward by keeping optimal settings\n",
    "    actions = [\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 100},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 150},\n",
    "        {\"paddle\": (1, 1), \"air_pump\": 1, \"lid\": 1, \"duration\": 200}\n",
    "    ]\n",
    "\n",
    "    for i, action in enumerate(actions):\n",
    "        print(f\"\\nRunning Step {i+1} with Action: {action}\")\n",
    "        full_action = {\n",
    "            \"active_chamber\": action,\n",
    "            \"curing_chamber\": action\n",
    "        }\n",
    "        obs, reward, done = simulate_step(full_action)\n",
    "\n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved, actions are aligned with optimal conditions!\")\n",
    "\n",
    "# Test Scenario 2: Gradual environmental response adjustments with variance in range\n",
    "def test_environment_response():\n",
    "    # Gradual changes with controlled variance for realistic values between 15 and 60\n",
    "    adjustments = [\n",
    "        {\"temperature\": random.uniform(1, 9), \"co2\": random.uniform(15, 60), \"moisture\": random.uniform(9, 14)},\n",
    "        {\"temperature\": random.uniform(3, 17), \"co2\": random.uniform(15, 60), \"moisture\": random.uniform(9, 24)},\n",
    "        {\"temperature\": random.uniform(1, 7), \"co2\": random.uniform(5, 6), \"moisture\": random.uniform(2, 66)},\n",
    "        {\"temperature\": random.uniform(15, 60), \"co2\": random.uniform(8, 23), \"moisture\": random.uniform(15, 60)},\n",
    "        {\"temperature\": random.uniform(15, 60), \"co2\": random.uniform(9, 11), \"moisture\": random.uniform(15, 60)}\n",
    "    ]\n",
    "\n",
    "    for i, adjustment in enumerate(adjustments):\n",
    "        print(f\"\\nEnvironment Adjustment Step {i+1}: {adjustment}\")\n",
    "        \n",
    "        # Apply controlled updates and slight random noise to each sensor, keeping values within 15-60\n",
    "        for chamber in [env.active_chamber, env.curing_chamber]:\n",
    "            chamber.update_temperature(np.clip(adjustment[\"temperature\"] + random.uniform(-1, 1), 15, 60))\n",
    "            chamber.update_co2(np.clip(adjustment[\"co2\"] + random.uniform(-1, 1), 15, 60))\n",
    "            chamber.update_moisture(np.clip(adjustment[\"moisture\"] + random.uniform(-1, 1), 15, 60))\n",
    "\n",
    "        # Simulate environment's natural state changes without actions\n",
    "        obs, reward, done = simulate_step({\"active_chamber\": {}, \"curing_chamber\": {}})\n",
    "        \n",
    "        if reward >= 0.8:\n",
    "            print(\"High reward achieved from environmental adjustment!\")\n",
    "\n",
    "# Run the tests\n",
    "print(\"Testing Compost Cycle\")\n",
    "test_compost_cycle()\n",
    "\n",
    "print(\"\\nTesting Environment Response\")\n",
    "test_environment_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e892e1cc-8170-4a1f-9b9a-15e8857bc7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Epsilon-greedy strategy for action selection\n",
    "def choose_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b69c26-18ab-4241-a833-31418f81ab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.05, moisture=55.3, oxygen=18.0, co2=18.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-94.95, moisture=60.95, oxygen=100.0, co2=5.04, methane=-71.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-44.41, moisture=-11.21, oxygen=100.0, co2=62.76, methane=-71.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=4.39, moisture=13.19, oxygen=100.0, co2=43.24, methane=-46.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.24000000000000002\n",
      "Checking extreme values for chamber: temp=-85.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-67.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=49.4, moisture=58.3, oxygen=23.1, co2=7.16, methane=-1.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=39.5, moisture=71.0, oxygen=49.5, co2=6.0, methane=-8.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=2.39, moisture=9.49, oxygen=100.0, co2=46.2, methane=-50.52\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.32\n",
      "Checking extreme values for chamber: temp=3.34, moisture=61.0, oxygen=86.1, co2=5.0, methane=-22.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-18.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-37.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-69.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-59.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=76.25, moisture=60.5, oxygen=18.0, co2=14.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m\n\u001b[0;32m     89\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     95\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 50\u001b[0m         state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m         q_values \u001b[38;5;241m=\u001b[39m policy_net(state_tensor)\n\u001b[0;32m     52\u001b[0m         action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got dict)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Epsilon-greedy strategy for action selection\n",
    "def choose_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40be903-da34-4aa8-8be5-870c25e81eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.05, moisture=55.3, oxygen=18.0, co2=18.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-94.95, moisture=60.95, oxygen=100.0, co2=5.04, methane=-71.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-44.41, moisture=-11.21, oxygen=100.0, co2=62.76, methane=-71.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=4.39, moisture=13.19, oxygen=100.0, co2=43.24, methane=-46.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.24000000000000002\n",
      "Checking extreme values for chamber: temp=-85.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-67.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=49.4, moisture=58.3, oxygen=23.1, co2=7.16, methane=-1.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=39.5, moisture=71.0, oxygen=49.5, co2=6.0, methane=-8.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=2.39, moisture=9.49, oxygen=100.0, co2=46.2, methane=-50.52\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.32\n",
      "Checking extreme values for chamber: temp=3.34, moisture=61.0, oxygen=86.1, co2=5.0, methane=-22.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-18.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-37.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-69.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-59.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=76.25, moisture=60.5, oxygen=18.0, co2=14.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m\n\u001b[0;32m     89\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     95\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 50\u001b[0m         state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m         q_values \u001b[38;5;241m=\u001b[39m policy_net(state_tensor)\n\u001b[0;32m     52\u001b[0m         action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got dict)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Epsilon-greedy strategy for action selection\n",
    "def choose_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cd7a65-44a0-4237-bcaa-91aaf85260ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=100.0, moisture=23.0, oxygen=15.0, co2=35.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=14.19, moisture=28.09, oxygen=100.0, co2=40.32, methane=-40.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=17.95, oxygen=14.97, co2=39.44, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=0.79, moisture=70.95, oxygen=100.0, co2=6.04, methane=-27.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.92\n",
      "Checking extreme values for chamber: temp=37.54, moisture=34.59, oxygen=94.2, co2=26.12, methane=-25.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.0, oxygen=15.0, co2=56.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.41000000000000003\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    113\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     52\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(state_values)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mactions[action_index]\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "def choose_action(state, epsilon):\n",
    "    # Flatten the state dictionary to a list\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "def flatten_state(state):\n",
    "    \"\"\"Flatten the nested state dictionary into a single list of sensor values.\"\"\"\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            # If values is an array, extend flat_state with all its elements\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                # Otherwise, append the single value\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55495ea-75c2-4050-93fc-62bb0bd0a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=15.19, moisture=18.59, oxygen=100.0, co2=38.92, methane=-41.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.24000000000000002\n",
      "Checking extreme values for chamber: temp=78.2, moisture=42.7, oxygen=15.0, co2=19.64, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.1, moisture=42.65, oxygen=14.97, co2=19.68, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=4.29, moisture=42.65, oxygen=100.0, co2=19.68, methane=-35.88\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 2.01\n",
      "Checking extreme values for chamber: temp=65.3, moisture=51.3, oxygen=15.0, co2=12.76, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=81.8, moisture=56.8, oxygen=18.0, co2=17.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=23.19, oxygen=15.0, co2=35.24, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=97.1, moisture=46.59, oxygen=18.0, co2=25.52, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.0, moisture=23.19, oxygen=16.5, co2=35.24, methane=0.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=51.29, moisture=46.59, oxygen=86.7, co2=25.52, methane=-20.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 1.23\n",
      "Checking extreme values for chamber: temp=43.25, moisture=46.0, oxygen=60.0, co2=17.0, methane=-14.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=13.09, moisture=71.0, oxygen=89.1, co2=6.0, methane=-21.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=37.58, moisture=34.7, oxygen=93.9, co2=26.04, methane=-25.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=-60.21, moisture=-19.11, oxygen=100.0, co2=69.08, methane=-79.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=69.65, moisture=48.4, oxygen=15.0, co2=15.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=23.69, moisture=71.0, oxygen=73.19, co2=6.0, methane=-16.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=-4.21, moisture=8.89, oxygen=100.0, co2=46.68, methane=-51.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-2.61, oxygen=15.0, co2=55.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-13.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-31.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=-20.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    113\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     52\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(state_values)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mactions[action_index]\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "def choose_action(state, epsilon):\n",
    "    # Flatten the state dictionary to a list\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "def flatten_state(state):\n",
    "    \"\"\"Flatten the nested state dictionary into a single list of sensor values.\"\"\"\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            # If values is an array, extend flat_state with all its elements\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                # Otherwise, append the single value\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8750f71-3ba5-40ec-8d28-16cf8b97704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=93.05, moisture=32.79, oxygen=15.0, co2=27.56, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=22.79, oxygen=18.0, co2=44.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=92.95, moisture=32.74, oxygen=14.97, co2=27.6, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-64.41, moisture=-59.41, oxygen=100.0, co2=110.32, methane=-80.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 1.52\n",
      "Checking extreme values for chamber: temp=-40.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-44.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-67.61, moisture=-22.86, oxygen=100.0, co2=72.08, methane=-82.79\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.41000000000000003\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dict' object has no attribute 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 108\u001b[0m\n\u001b[0;32m    104\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    110\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[5], line 68\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     66\u001b[0m q_values \u001b[38;5;241m=\u001b[39m policy_net(state_tensor)\n\u001b[0;32m     67\u001b[0m action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m[action_index]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dict' object has no attribute 'actions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Modify the state input to ensure it is a sequence, not a dictionary\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)  # Flatten the state dictionary\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((flatten_state(state), action, reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb6b015-5f8c-47b8-a136-717a9edb198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=100.0, moisture=12.0, oxygen=15.0, co2=44.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=39.7, moisture=71.0, oxygen=49.2, co2=6.0, methane=-8.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=53.4, moisture=12.0, oxygen=84.9, co2=44.2, methane=-22.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.61\n",
      "Checking extreme values for chamber: temp=94.25, moisture=32.0, oxygen=15.0, co2=28.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=77.25, moisture=32.0, oxygen=40.5, co2=28.2, methane=-7.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-10.81, moisture=70.95, oxygen=100.0, co2=6.04, methane=-33.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 1.1099999999999999\n",
      "Checking extreme values for chamber: temp=30.2, moisture=26.1, oxygen=100.0, co2=32.92, methane=-33.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=13.09, oxygen=18.0, co2=52.32, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-47.91, oxygen=18.0, co2=101.12, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.8200000000000001\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-9.91, oxygen=15.0, co2=61.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-43.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-46.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-51.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-47.76, moisture=60.95, oxygen=100.0, co2=5.04, methane=-48.18\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=44.0, moisture=47.5, oxygen=55.5, co2=15.8, methane=-12.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=26.69, oxygen=18.0, co2=41.44, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.09000000000000002, oxygen=55.5, co2=53.72, methane=-12.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=16.59, moisture=19.29, oxygen=100.0, co2=38.36, methane=-40.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.24000000000000002\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.609999999999999, oxygen=15.0, co2=59.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.6, oxygen=15.0, co2=31.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=29.7, moisture=71.0, oxygen=64.19, co2=6.0, methane=-13.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.9, oxygen=15.0, co2=60.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.8200000000000001\n",
      "Checking extreme values for chamber: temp=87.05, moisture=36.79, oxygen=15.0, co2=24.36, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-2.92, oxygen=15.0, co2=56.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 1.17\n",
      "Checking extreme values for chamber: temp=33.15, moisture=61.0, oxygen=41.4, co2=5.0, methane=-7.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-37.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.12\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=94.69, moisture=31.700000000000003, oxygen=15.0, co2=28.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-50.11, oxygen=15.0, co2=93.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 1.17\n",
      "Checking extreme values for chamber: temp=93.8, moisture=32.29, oxygen=15.0, co2=27.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=55.2, moisture=60.4, oxygen=49.8, co2=14.48, methane=-8.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    113\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[6], line 53\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     52\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(state_values)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mactions[action_index]\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "def choose_action(state, epsilon):\n",
    "    # Flatten the state dictionary to a list\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "def flatten_state(state):\n",
    "    \"\"\"Flatten the nested state dictionary into a single list of sensor values.\"\"\"\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            # If values is an array, extend flat_state with all its elements\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                # Otherwise, append the single value\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0a87ca-3c0f-4f56-80bf-80e623cc5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-87.9, moisture=71.0, oxygen=100.0, co2=6.0, methane=-72.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-33.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-41.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=-44.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.6100000000000003, oxygen=15.0, co2=56.68, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=54.2, moisture=58.7, oxygen=15.0, co2=6.84, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=54.1, moisture=58.65, oxygen=14.97, co2=6.88, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.59, moisture=42.25, oxygen=100.0, co2=29.0, methane=-26.69\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.8200000000000001\n",
      "Checking extreme values for chamber: temp=66.34, moisture=50.6, oxygen=15.0, co2=13.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=26.9, moisture=71.0, oxygen=68.4, co2=6.0, methane=-14.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=7.0, oxygen=15.0, co2=48.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.8200000000000001\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-28.5, oxygen=15.0, co2=76.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-40.21, moisture=0.8899999999999999, oxygen=100.0, co2=62.08, methane=-68.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=72.95, moisture=46.2, oxygen=15.0, co2=16.84, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.3, moisture=71.0, oxygen=21.3, co2=6.0, methane=0.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=20.5, oxygen=15.0, co2=37.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.2, moisture=70.95, oxygen=21.27, co2=6.04, methane=0.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=20.45, oxygen=14.97, co2=37.44, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=43.2, moisture=70.95, oxygen=43.77, co2=6.04, methane=-6.59\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.8, moisture=20.395, oxygen=14.94, co2=37.47, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-41.0, moisture=0.44999999999999996, oxygen=100.0, co2=62.44, methane=-77.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 1.9900000000000002\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=86.0, moisture=54.0, oxygen=18.0, co2=19.6, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-41.35, moisture=60.95, oxygen=100.0, co2=5.04, methane=-44.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-44.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    113\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     52\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(state_values)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mactions[action_index]\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18 and 2x128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and model\n",
    "env = CompostingEnv()\n",
    "state_dim = len(env.reset())  # Get the dimension of the state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer\n",
    "policy_net = DQN(state_dim, action_dim)\n",
    "target_net = DQN(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "def choose_action(state, epsilon):\n",
    "    # Flatten the state dictionary to a list\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "def flatten_state(state):\n",
    "    \"\"\"Flatten the nested state dictionary into a single list of sensor values.\"\"\"\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            # If values is an array, extend flat_state with all its elements\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                # Otherwise, append the single value\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90013710-725c-4b06-99f5-61e354d3bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=11.34, moisture=61.0, oxygen=74.09, co2=5.0, methane=-18.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=53.15, moisture=59.4, oxygen=15.0, co2=6.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-64.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-60.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=23.0, moisture=32.5, oxygen=100.0, co2=36.79, methane=-36.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-84.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.0\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=54.1, moisture=71.0, oxygen=27.6, co2=6.0, methane=-1.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=45.65, moisture=50.95, oxygen=44.97, co2=13.04, methane=-8.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.19, oxygen=27.6, co2=45.84, methane=-1.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=67.7, moisture=36.25, oxygen=44.97, co2=24.79, methane=-8.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=21.14, oxygen=27.57, co2=45.88, methane=-1.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=67.6, moisture=36.2, oxygen=44.94, co2=24.83, methane=-8.97\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-21.91, moisture=21.14, oxygen=100.0, co2=45.88, methane=-62.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 1.1099999999999999\n",
      "Checking extreme values for chamber: temp=38.95, moisture=61.0, oxygen=32.7, co2=5.0, methane=-4.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-56.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-56.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=93.94, moisture=48.7, oxygen=18.0, co2=23.84, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.25, moisture=56.55, oxygen=14.97, co2=8.56, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-2.71, oxygen=18.0, co2=64.95, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.8200000000000001\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.5, oxygen=15.0, co2=31.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-13.41, moisture=14.29, oxygen=100.0, co2=51.36, methane=-54.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.41000000000000003\n",
      "Checking extreme values for chamber: temp=41.5, moisture=42.5, oxygen=70.5, co2=19.8, methane=-17.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dict' object has no attribute 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 108\u001b[0m\n\u001b[0;32m    104\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    110\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     66\u001b[0m q_values \u001b[38;5;241m=\u001b[39m policy_net(state_tensor)\n\u001b[0;32m     67\u001b[0m action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m[action_index]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dict' object has no attribute 'actions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Modify the state input to ensure it is a sequence, not a dictionary\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)  # Flatten the state dictionary\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((flatten_state(state), action, reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7223f54-73ec-40a8-b8af-df5b47f811dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=51.7, moisture=71.0, oxygen=31.2, co2=6.0, methane=-2.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-14.56, moisture=60.95, oxygen=100.0, co2=5.04, methane=-31.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-76.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-54.61, moisture=-16.36, oxygen=100.0, co2=66.88, methane=-76.29\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-87.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=6.29, oxygen=18.0, co2=57.76, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-52.41, moisture=-15.21, oxygen=100.0, co2=65.96, methane=-75.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=35.14, moisture=29.79, oxygen=100.0, co2=29.96, methane=-30.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=47.15, moisture=53.8, oxygen=36.59, co2=10.76, methane=-6.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-74.61, moisture=-16.31, oxygen=100.0, co2=75.84, methane=-85.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=83.0, moisture=56.0, oxygen=18.0, co2=18.0, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=41.445, moisture=60.95, oxygen=28.77, co2=5.04, methane=-3.59\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.8100000000000005, oxygen=18.0, co2=69.03, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-84.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-66.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-47.6, moisture=-2.8, oxygen=100.0, co2=65.03, methane=-71.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=4.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-26.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-0.45999999999999996, moisture=61.0, oxygen=91.8, co2=5.0, methane=-24.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=40.59, moisture=41.295, oxygen=100.0, co2=29.76, methane=-27.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=26.59, moisture=24.29, oxygen=100.0, co2=34.36, methane=-35.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-13.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-30.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 16, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=15.79, oxygen=15.0, co2=41.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-16.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-36.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 17, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.45, moisture=70.9, oxygen=18.3, co2=6.08, methane=1.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=60.95, oxygen=100.0, co2=5.04, methane=-82.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 18, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=59.3, moisture=55.3, oxygen=15.0, co2=9.56, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-1.1099999999999999, oxygen=18.0, co2=63.68, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 19, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-15.41, moisture=3.29, oxygen=100.0, co2=51.16, methane=-56.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 20, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-10.61, moisture=15.690000000000001, oxygen=100.0, co2=50.24, methane=-53.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 21, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-18.0, moisture=2.0, oxygen=100.0, co2=52.2, methane=-58.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 22, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=43.4, oxygen=18.0, co2=28.08, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dict' object has no attribute 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 108\u001b[0m\n\u001b[0;32m    104\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Select action based on epsilon-greedy strategy\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    110\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[9], line 68\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m     66\u001b[0m q_values \u001b[38;5;241m=\u001b[39m policy_net(state_tensor)\n\u001b[0;32m     67\u001b[0m action_index \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m[action_index]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dict' object has no attribute 'actions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Modify the state input to ensure it is a sequence, not a dictionary\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)  # Flatten the state dictionary\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()  # Select a random action\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return env.action_space.actions[action_index]\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((flatten_state(state), action, reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    # Print total reward with two decimal places\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe0d9d6b-701e-4cf4-bdbf-a8ff86e40c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=100.0, moisture=-19.91, oxygen=15.0, co2=69.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=67.84, moisture=49.6, oxygen=15.0, co2=14.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=15.39, oxygen=18.0, co2=50.48, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-25.1, oxygen=15.0, co2=73.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-91.71, moisture=71.0, oxygen=100.0, co2=6.0, methane=-74.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=45.65, moisture=50.95, oxygen=44.97, co2=13.04, methane=-8.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=8.54, oxygen=17.97, co2=55.96, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=22.0, moisture=22.0, oxygen=100.0, co2=36.2, methane=-38.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-4.61, moisture=18.69, oxygen=100.0, co2=47.84, methane=-50.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=35.39, moisture=38.69, oxygen=100.0, co2=31.84, methane=-30.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-60.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-54.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=39.0, moisture=37.5, oxygen=85.5, co2=23.8, methane=-22.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=-74.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-61.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-71.41, moisture=-24.71, oxygen=100.0, co2=73.56, methane=-84.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-32.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-40.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-17.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-33.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-35.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-42.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=4.75, moisture=61.0, oxygen=84.0, co2=5.0, methane=-22.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-79.0, moisture=-28.5, oxygen=100.0, co2=76.6, methane=-88.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 16, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-75.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 17, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=17.5, oxygen=15.0, co2=39.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.61, moisture=7.1899999999999995, oxygen=100.0, co2=57.04, methane=-61.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 18, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-14.8, oxygen=15.0, co2=65.64, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 19, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=17.04, moisture=60.95, oxygen=65.37, co2=5.04, methane=-15.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-57.21, moisture=70.95, oxygen=100.0, co2=6.04, methane=-56.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 20, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=-36.6, moisture=-7.300000000000001, oxygen=100.0, co2=59.64, methane=-67.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 21, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-44.41, moisture=-11.21, oxygen=100.0, co2=62.76, methane=-71.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 22, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=25.0, oxygen=15.0, co2=33.79, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=90.5, moisture=51.0, oxygen=18.0, co2=22.0, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=65.4, moisture=25.0, oxygen=66.9, co2=33.79, methane=-16.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=89.65, moisture=49.3, oxygen=23.1, co2=23.36, methane=0.29\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=65.3, moisture=24.95, oxygen=66.87, co2=33.83, methane=-16.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=89.55, moisture=49.25, oxygen=23.07, co2=23.4, methane=0.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-3.31, moisture=24.95, oxygen=100.0, co2=33.83, methane=-50.59\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 23, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=26.39, moisture=34.19, oxygen=100.0, co2=35.44, methane=-34.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 24, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.35, oxygen=14.97, co2=62.08, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 136\u001b[0m\n\u001b[0;32m    133\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Update the model\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     \u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Update the target network periodically\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m TARGET_UPDATE_FREQUENCY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[10], line 105\u001b[0m, in \u001b[0;36mupdate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay_buffer) \u001b[38;5;241m<\u001b[39m BATCH_SIZE:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[43msample_from_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m q_values \u001b[38;5;241m=\u001b[39m policy_net(states)\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m target_net(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[10], line 95\u001b[0m, in \u001b[0;36msample_from_buffer\u001b[1;34m(buffer, batch_size)\u001b[0m\n\u001b[0;32m     91\u001b[0m batch \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(buffer, batch_size)\n\u001b[0;32m     92\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     94\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(states),\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(rewards),\n\u001b[0;32m     97\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(next_states),\n\u001b[0;32m     98\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(dones),\n\u001b[0;32m     99\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Modify the state input to ensure it is a sequence, not a dictionary\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)  # Flatten the state dictionary\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return generate_random_action()  # Use the new function for random actions\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            # Map `action_index` to a predefined action if needed or customize based on learned policy\n",
    "            return generate_random_action()\n",
    "\n",
    "def generate_random_action():\n",
    "    \"\"\"Generate a random action compatible with the dictionary action space.\"\"\"\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Sampling from the replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.LongTensor(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action based on epsilon-greedy strategy\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store experience in replay buffer\n",
    "        replay_buffer.append((flatten_state(state), action, reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        # Update the model\n",
    "        update_model()\n",
    "\n",
    "    # Update the target network periodically\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Gradually decrease epsilon\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    # Print total reward with two decimal places\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b801343-e2e2-4b69-af87-4ecb64ccda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=-45.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-47.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-86.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-47.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-48.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=30.15, moisture=61.0, oxygen=45.9, co2=5.0, methane=-9.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-55.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-56.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-26.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-37.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=34.75, moisture=29.0, oxygen=100.0, co2=30.6, methane=-31.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-17.21, moisture=12.39, oxygen=100.0, co2=52.88, methane=-56.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-42.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-45.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-13.61, moisture=4.19, oxygen=100.0, co2=50.44, methane=-55.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=60.8, moisture=54.3, oxygen=15.0, co2=10.36, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.5, moisture=71.0, oxygen=22.5, co2=6.0, methane=0.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.61, oxygen=15.0, co2=62.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.8, oxygen=15.0, co2=62.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-19.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=32.095, moisture=71.0, oxygen=60.6, co2=6.0, methane=-12.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-37.6, moisture=-7.85, oxygen=100.0, co2=60.08, methane=-67.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-87.71, moisture=71.0, oxygen=100.0, co2=6.0, methane=-72.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=12.34, moisture=61.0, oxygen=72.59, co2=5.0, methane=-18.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=100.0, moisture=10.29, oxygen=15.0, co2=45.56, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=56.54, moisture=63.095, oxygen=41.7, co2=12.32, methane=-5.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-4.61, moisture=-42.02, oxygen=100.0, co2=87.4, methane=-51.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 16, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=-37.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 17, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-12.81, moisture=4.59, oxygen=100.0, co2=50.12, methane=-55.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 18, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-42.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-45.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 19, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=48.05, moisture=55.6, oxygen=31.2, co2=9.32, methane=-4.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=47.95, moisture=55.55, oxygen=31.17, co2=9.36, methane=-4.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=61.6, moisture=70.15, oxygen=17.97, co2=6.68, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=2.39, moisture=6.74, oxygen=100.0, co2=48.4, methane=-53.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 20, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=41.09, moisture=71.0, oxygen=47.09, co2=6.0, methane=-7.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-14.96, moisture=60.95, oxygen=100.0, co2=5.04, methane=-31.79\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 21, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=22.39, moisture=32.19, oxygen=100.0, co2=37.04, methane=-36.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 22, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-14.61, moisture=3.6900000000000004, oxygen=100.0, co2=50.84, methane=-56.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 23, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=25.59, moisture=23.79, oxygen=100.0, co2=34.76, methane=-36.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 24, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.3, moisture=60.1, oxygen=17.7, co2=5.72, methane=0.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=66.65, moisture=66.9, oxygen=18.0, co2=9.28, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.2, moisture=60.05, oxygen=17.66, co2=5.76, methane=0.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-77.21, moisture=-21.71, oxygen=100.0, co2=80.16, methane=-86.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 160\u001b[0m\n\u001b[0;32m    157\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n\u001b[0;32m    158\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m--> 160\u001b[0m     \u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m TARGET_UPDATE_FREQUENCY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    163\u001b[0m     target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Cell \u001b[1;32mIn[11], line 133\u001b[0m, in \u001b[0;36mupdate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    131\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m sample_from_buffer(replay_buffer, BATCH_SIZE)\n\u001b[1;32m--> 133\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    134\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m target_net(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    135\u001b[0m expected_q_values \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (GAMMA \u001b[38;5;241m*\u001b[39m next_q_values \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Encode and decode action for storage compatibility\n",
    "def encode_action(action):\n",
    "    active_chamber_action = action['active_chamber']\n",
    "    curing_chamber_action = action['curing_chamber']\n",
    "    return (\n",
    "        (active_chamber_action['paddle'][0], active_chamber_action['paddle'][1],\n",
    "         active_chamber_action['air_pump'], active_chamber_action['lid'], active_chamber_action['duration']),\n",
    "        (curing_chamber_action['paddle'][0], curing_chamber_action['paddle'][1],\n",
    "         curing_chamber_action['air_pump'], curing_chamber_action['lid'], curing_chamber_action['duration'])\n",
    "    )\n",
    "\n",
    "def decode_action(encoded_action):\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (encoded_action[0][0], encoded_action[0][1]),\n",
    "            \"air_pump\": encoded_action[0][2],\n",
    "            \"lid\": encoded_action[0][3],\n",
    "            \"duration\": encoded_action[0][4]\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (encoded_action[1][0], encoded_action[1][1]),\n",
    "            \"air_pump\": encoded_action[1][2],\n",
    "            \"lid\": encoded_action[1][3],\n",
    "            \"duration\": encoded_action[1][4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Generate random action compatible with the environment's dictionary action space\n",
    "def generate_random_action():\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Choose action using epsilon-greedy strategy\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return generate_random_action()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return generate_random_action()  # Return random action for simplicity\n",
    "\n",
    "# Sample from replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, encoded_actions, rewards, next_states, dones = zip(*batch)\n",
    "    actions = [torch.FloatTensor([*action[0], *action[1]]) for action in encoded_actions]\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.stack(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions.unsqueeze(1).long()).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store encoded action\n",
    "        replay_buffer.append((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        update_model()\n",
    "\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663d89e2-66cc-465c-8e4c-85117d776e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=34.95, moisture=61.0, oxygen=38.7, co2=5.0, methane=-6.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.29000000000000004, oxygen=18.0, co2=62.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=40.45, moisture=40.4, oxygen=76.8, co2=21.48, methane=-19.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=25.0, oxygen=18.0, co2=42.8, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-56.0, oxygen=18.0, co2=107.6, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-4.41, oxygen=18.0, co2=66.31, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-29.41, moisture=-3.71, oxygen=100.0, co2=56.76, methane=-63.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=54.85, moisture=59.7, oxygen=51.9, co2=15.04, methane=-9.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-26.35, moisture=60.95, oxygen=100.0, co2=5.04, methane=-37.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=43.65, moisture=60.95, oxygen=25.47, co2=5.04, methane=-2.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-55.21, moisture=-6.66, oxygen=100.0, co2=68.12, methane=-75.59\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.09, moisture=43.85, oxygen=66.27, co2=18.72, methane=-16.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-13.66, oxygen=17.97, co2=73.72, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=77.75, moisture=59.5, oxygen=18.0, co2=15.2, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=77.65, moisture=59.45, oxygen=17.97, co2=15.23, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.45, moisture=60.85, oxygen=14.91, co2=5.12, methane=1.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-69.61, moisture=-25.36, oxygen=100.0, co2=83.07, methane=-82.79\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 1.23\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-0.81, oxygen=15.0, co2=54.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=86.45, moisture=53.7, oxygen=18.0, co2=19.84, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.84, moisture=60.95, oxygen=26.67, co2=5.04, methane=-2.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.3, oxygen=18.0, co2=47.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.14, moisture=50.75, oxygen=26.67, co2=13.2, methane=-2.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=21.19, moisture=-20.11, oxygen=100.0, co2=78.88, methane=-37.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=8.5, oxygen=15.0, co2=47.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.8, oxygen=15.0, co2=62.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-40.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-44.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=36.53, moisture=32.75, oxygen=99.57, co2=27.6, methane=-27.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 0.90\n",
      "Checking extreme values for chamber: temp=-66.0, moisture=-22.0, oxygen=100.0, co2=71.4, methane=-82.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 16, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=33.870000000000005, moisture=28.1, oxygen=100.0, co2=31.32, methane=-31.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 17, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=26.59, moisture=24.25, oxygen=100.0, co2=34.4, methane=-35.68\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 18, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.2, moisture=60.05, oxygen=17.67, co2=5.76, methane=0.12\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-58.0, moisture=-8.05, oxygen=100.0, co2=69.24, methane=-76.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 19, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=11.0, oxygen=15.0, co2=45.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-5.0, moisture=-41.5, oxygen=100.0, co2=87.0, methane=-51.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 0 expected index [320, 1] to be smaller than self [32, 4] apart from dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 164\u001b[0m\n\u001b[0;32m    161\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n\u001b[0;32m    162\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m--> 164\u001b[0m     \u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m TARGET_UPDATE_FREQUENCY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    167\u001b[0m     target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Cell \u001b[1;32mIn[12], line 135\u001b[0m, in \u001b[0;36mupdate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m sample_from_buffer(replay_buffer, BATCH_SIZE)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Ensure actions are in the correct shape for gathering\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    136\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m target_net(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    137\u001b[0m expected_q_values \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (GAMMA \u001b[38;5;241m*\u001b[39m next_q_values \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Size does not match at dimension 0 expected index [320, 1] to be smaller than self [32, 4] apart from dimension 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Encode and decode action for storage compatibility\n",
    "def encode_action(action):\n",
    "    active_chamber_action = action['active_chamber']\n",
    "    curing_chamber_action = action['curing_chamber']\n",
    "    return (\n",
    "        (active_chamber_action['paddle'][0], active_chamber_action['paddle'][1],\n",
    "         active_chamber_action['air_pump'], active_chamber_action['lid'], active_chamber_action['duration']),\n",
    "        (curing_chamber_action['paddle'][0], curing_chamber_action['paddle'][1],\n",
    "         curing_chamber_action['air_pump'], curing_chamber_action['lid'], curing_chamber_action['duration'])\n",
    "    )\n",
    "\n",
    "def decode_action(encoded_action):\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (encoded_action[0][0], encoded_action[0][1]),\n",
    "            \"air_pump\": encoded_action[0][2],\n",
    "            \"lid\": encoded_action[0][3],\n",
    "            \"duration\": encoded_action[0][4]\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (encoded_action[1][0], encoded_action[1][1]),\n",
    "            \"air_pump\": encoded_action[1][2],\n",
    "            \"lid\": encoded_action[1][3],\n",
    "            \"duration\": encoded_action[1][4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Generate random action compatible with the environment's dictionary action space\n",
    "def generate_random_action():\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Choose action using epsilon-greedy strategy\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return generate_random_action()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return generate_random_action()  # Return random action for simplicity\n",
    "\n",
    "# Sample from replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, encoded_actions, rewards, next_states, dones = zip(*batch)\n",
    "    actions = [torch.FloatTensor([*action[0], *action[1]]) for action in encoded_actions]\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        torch.stack(actions),\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "    \n",
    "    # Ensure actions are in the correct shape for gathering\n",
    "    q_values = policy_net(states).gather(1, actions.view(-1, 1).long()).squeeze(1)\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    # Compute and apply the loss\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store encoded action\n",
    "        replay_buffer.append((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        update_model()\n",
    "\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b21b2fb0-f3d7-4cd7-ae77-c02836c255a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (286445138.py, line 186)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 186\u001b[1;36m\u001b[0m\n\u001b[1;33m    }\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Encode and decode action for storage compatibility\n",
    "def encode_action(action):\n",
    "    active_chamber_action = action['active_chamber']\n",
    "    curing_chamber_action = action['curing_chamber']\n",
    "    return (\n",
    "        (active_chamber_action['paddle'][0], active_chamber_action['paddle'][1],\n",
    "         active_chamber_action['air_pump'], active_chamber_action['lid'], active_chamber_action['duration']),\n",
    "        (curing_chamber_action['paddle'][0], curing_chamber_action['paddle'][1],\n",
    "         curing_chamber_action['air_pump'], curing_chamber_action['lid'], curing_chamber_action['duration'])\n",
    "    )\n",
    "\n",
    "def decode_action(encoded_action):\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (encoded_action[0][0], encoded_action[0][1]),\n",
    "            \"air_pump\": encoded_action[0][2],\n",
    "            \"lid\": encoded_action[0][3],\n",
    "            \"duration\": encoded_action[0][4]\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (encoded_action[1][0], encoded_action[1][1]),\n",
    "            \"air_pump\": encoded_action[1][2],\n",
    "            \"lid\": encoded_action[1][3],\n",
    "            \"duration\": encoded_action[1][4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Generate random action compatible with the environment's dictionary action space\n",
    "def generate_random_action():\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Choose action using epsilon-greedy strategy\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return generate_random_action()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return generate_random_action()  # Return random action for simplicity\n",
    "\n",
    "# Sample from replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, encoded_actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "    # Extract a scalar or index from the encoded actions for indexing Q-values\n",
    "    # Example: Using only the \"air_pump\" action as a scalar index for simplicity\n",
    "    actions = torch.LongTensor([action[0][2] for action in encoded_actions])  # Just an example\n",
    "\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        actions,\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    # Sample from replay buffer and extract components\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "    \n",
    "    # Get Q-values for the current policy network\n",
    "    q_values = policy_net(states)  # Output shape [BATCH_SIZE, action_dim]\n",
    "\n",
    "    # Use actions to gather specific Q-values from policy_net\n",
    "    q_values = q_values.gather(1, actions.view(-1, 1).long()).squeeze(1)  # Shape [BATCH_SIZE]\n",
    "    \n",
    "    # Calculate next Q-values from target network\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    # Compute loss and perform a backward pass\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store encoded action\n",
    "        replay_buffer.append((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        update_model()\n",
    "\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c768251a-d5b6-4a2e-b9d4-ee3cfd6626a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extreme values for chamber: temp=55.1, moisture=58.1, oxygen=15.0, co2=7.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.1100000000000003, oxygen=15.0, co2=56.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 1, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=35.75, moisture=61.0, oxygen=37.5, co2=5.0, methane=-6.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=40.09, moisture=71.0, oxygen=48.59, co2=6.0, methane=-8.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-27.81, oxygen=37.5, co2=76.04, methane=-6.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 2, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-46.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-47.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 3, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-24.0, oxygen=15.0, co2=73.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 4, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.5, oxygen=15.0, co2=53.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 5, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-32.21, moisture=-5.16, oxygen=100.0, co2=57.92, methane=-65.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 6, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-10.21, moisture=5.89, oxygen=100.0, co2=49.08, methane=-54.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 7, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=68.45, moisture=65.7, oxygen=18.0, co2=10.24, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=65.89, moisture=60.6, oxygen=33.29, co2=14.32, methane=-3.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.45, moisture=60.85, oxygen=14.91, co2=5.12, methane=1.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=65.79, moisture=60.55, oxygen=33.26, co2=14.36, methane=-3.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=75.2, moisture=44.35, oxygen=14.91, co2=18.32, methane=1.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.5599999999999996, oxygen=33.26, co2=65.64, methane=-3.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 8, Total Reward: 1.99\n",
      "Checking extreme values for chamber: temp=-73.81, moisture=-25.91, oxygen=100.0, co2=74.52, methane=-85.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 9, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=26.95, moisture=61.0, oxygen=50.7, co2=5.0, methane=-10.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=15.190000000000001, oxygen=18.0, co2=50.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.91, oxygen=50.7, co2=68.92, methane=-10.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 10, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-79.61, moisture=-28.81, oxygen=100.0, co2=76.84, methane=-88.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 11, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.0, oxygen=15.0, co2=61.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 12, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-41.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-49.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 13, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-54.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-51.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 14, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=20.95, moisture=61.0, oxygen=59.7, co2=5.0, methane=-13.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=35.19, oxygen=18.0, co2=34.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-60.41, moisture=-19.21, oxygen=100.0, co2=69.16, methane=-94.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 15, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=15.79, moisture=18.89, oxygen=100.0, co2=38.68, methane=-41.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 16, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=53.0, moisture=59.5, oxygen=15.0, co2=6.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=10.09, oxygen=18.0, co2=54.72, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=52.9, moisture=59.45, oxygen=14.97, co2=6.24, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=10.035, oxygen=17.97, co2=54.76, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-61.1, moisture=59.45, oxygen=100.0, co2=6.24, methane=-55.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 17, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-14.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-31.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 18, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-26.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-37.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 19, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-53.81, moisture=-15.91, oxygen=100.0, co2=66.52, methane=-75.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 20, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-70.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-59.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 21, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=85.1, moisture=38.09, oxygen=15.0, co2=23.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=76.55, moisture=60.3, oxygen=18.0, co2=14.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.49, oxygen=15.0, co2=31.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-90.45, moisture=60.3, oxygen=100.0, co2=14.56, methane=-81.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 22, Total Reward: 1.17\n",
      "Checking extreme values for chamber: temp=100.0, moisture=11.39, oxygen=15.0, co2=44.68, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=5.89, oxygen=15.0, co2=49.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 23, Total Reward: 0.92\n",
      "Checking extreme values for chamber: temp=84.5, moisture=38.5, oxygen=15.0, co2=23.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-70.21, moisture=-14.11, oxygen=100.0, co2=74.08, methane=-83.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 24, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=17.69, oxygen=18.0, co2=48.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=17.64, oxygen=17.97, co2=48.68, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=75.89, moisture=44.0, oxygen=14.94, co2=18.6, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=14.0, moisture=-25.36, oxygen=100.0, co2=83.08, methane=-40.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 25, Total Reward: 1.58\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=47.84, moisture=45.85, oxygen=93.27, co2=26.12, methane=-23.08\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 26, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-9.0, moisture=6.5, oxygen=100.0, co2=48.6, methane=-53.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 27, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-4.61, oxygen=15.0, co2=57.48, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 28, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-75.71, moisture=71.0, oxygen=100.0, co2=6.0, methane=-66.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 29, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-1.61, moisture=20.19, oxygen=100.0, co2=46.64, methane=-48.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 30, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-11.76, moisture=60.95, oxygen=100.0, co2=5.04, methane=-30.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 31, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-35.21, moisture=-6.61, oxygen=100.0, co2=59.08, methane=-66.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 32, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=78.05, moisture=42.8, oxygen=15.0, co2=19.56, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-25.0, moisture=-19.71, oxygen=100.0, co2=69.56, methane=-61.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 33, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.71, oxygen=18.0, co2=65.75, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 34, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-17.0, moisture=12.5, oxygen=100.0, co2=52.8, methane=-56.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 35, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=65.3, moisture=51.3, oxygen=15.0, co2=12.76, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-1.21, moisture=0.69, oxygen=100.0, co2=53.24, methane=-49.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 36, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=2.19, moisture=12.09, oxygen=100.0, co2=44.12, methane=-47.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 37, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-0.61, moisture=10.64, oxygen=100.0, co2=45.28, methane=-49.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 38, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-15.309999999999999, oxygen=18.0, co2=75.04, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 39, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=47.35, moisture=61.0, oxygen=20.1, co2=5.0, methane=-0.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-89.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-73.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 40, Total Reward: 0.18\n",
      "Checking extreme values for chamber: temp=41.79, moisture=43.09, oxygen=68.69, co2=19.32, methane=-16.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.51, oxygen=68.69, co2=59.8, methane=-16.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 41, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=-38.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 42, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=10.75, moisture=61.0, oxygen=75.0, co2=5.0, methane=-19.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 43, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.5, oxygen=15.0, co2=67.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 44, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-39.41, moisture=1.29, oxygen=100.0, co2=61.76, methane=-67.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 45, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-16.21, moisture=2.89, oxygen=100.0, co2=51.48, methane=-57.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 46, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=20.895, oxygen=15.0, co2=37.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-60.21, moisture=-59.215, oxygen=100.0, co2=101.16, methane=-79.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 47, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=64.4, moisture=51.9, oxygen=15.0, co2=12.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.69, oxygen=18.0, co2=40.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=2.1950000000000003, moisture=51.9, oxygen=100.0, co2=12.28, methane=-30.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 48, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=-27.21, moisture=-2.61, oxygen=100.0, co2=55.88, methane=-62.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 49, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=3.3899999999999997, oxygen=15.0, co2=51.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 50, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-11.16, oxygen=17.97, co2=71.72, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 51, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=60.2, moisture=54.7, oxygen=15.0, co2=10.03, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-49.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-52.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 52, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=26.69, oxygen=15.0, co2=32.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=2.29, oxygen=18.0, co2=60.96, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 53, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=34.660000000000004, moisture=28.9, oxygen=100.0, co2=30.68, methane=-31.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 54, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=46.75, moisture=53.0, oxygen=39.0, co2=11.4, methane=-7.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=0.19, moisture=21.09, oxygen=100.0, co2=45.92, methane=-47.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 55, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.5, oxygen=15.0, co2=68.59, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 56, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=63.2, moisture=52.7, oxygen=15.0, co2=11.64, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=25.39, moisture=33.69, oxygen=100.0, co2=35.84, methane=-35.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 57, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-27.91, oxygen=15.0, co2=76.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 58, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=66.05, moisture=50.8, oxygen=15.0, co2=13.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=49.95, moisture=49.9, oxygen=81.3, co2=22.88, methane=-19.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 59, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-48.0, moisture=-13.0, oxygen=100.0, co2=64.2, methane=-73.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 60, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=39.54, moisture=38.59, oxygen=82.2, co2=22.92, methane=-21.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 61, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=100.0, moisture=13.09, oxygen=15.0, co2=43.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.65, moisture=54.9, oxygen=18.0, co2=18.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=13.04, oxygen=14.97, co2=43.36, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.55, moisture=54.85, oxygen=17.97, co2=18.91, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.8, moisture=12.98, oxygen=14.94, co2=43.4, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.45, moisture=54.8, oxygen=17.93, co2=18.95, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.7, moisture=12.93, oxygen=14.91, co2=43.44, methane=1.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.69, oxygen=17.93, co2=55.03, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 62, Total Reward: 2.04\n",
      "Checking extreme values for chamber: temp=45.35, moisture=61.0, oxygen=23.1, co2=5.0, methane=-1.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=64.55, moisture=48.2, oxygen=23.1, co2=15.24, methane=-1.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=13.59, moisture=5.0, oxygen=100.0, co2=49.8, methane=-44.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 63, Total Reward: 0.85\n",
      "Checking extreme values for chamber: temp=100.0, moisture=12.0, oxygen=15.0, co2=44.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-8.81, moisture=-42.41, oxygen=100.0, co2=87.72, methane=-53.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 64, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=45.89, moisture=51.3, oxygen=44.09, co2=12.76, methane=-8.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=42.8, oxygen=18.0, co2=28.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.89, moisture=25.29, oxygen=44.09, co2=33.56, methane=-8.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-1.81, oxygen=18.0, co2=64.23, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 65, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-31.81, moisture=-4.91, oxygen=100.0, co2=57.72, methane=-64.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 66, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-20.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 67, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=48.5, moisture=56.5, oxygen=28.5, co2=8.6, methane=-3.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=35.19, oxygen=18.0, co2=34.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-24.61, moisture=-5.81, oxygen=100.0, co2=58.44, methane=-65.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 68, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-21.41, moisture=0.29000000000000004, oxygen=100.0, co2=53.56, methane=-59.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 69, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-64.21, moisture=-21.11, oxygen=100.0, co2=70.68, methane=-81.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 70, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-0.06000000000000005, moisture=61.0, oxygen=91.2, co2=5.0, methane=-24.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 71, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-9.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-29.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 72, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=48.55, moisture=56.6, oxygen=28.2, co2=8.52, methane=-3.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=17.5, oxygen=18.0, co2=48.8, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-59.41, moisture=-23.1, oxygen=100.0, co2=72.28, methane=-83.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 73, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=45.25, moisture=50.0, oxygen=48.0, co2=13.8, methane=-10.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-22.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-39.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 74, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=46.7, moisture=52.9, oxygen=39.29, co2=11.48, methane=-7.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=48.95, moisture=47.9, oxygen=87.3, co2=24.48, methane=-21.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 75, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=95.9, moisture=47.4, oxygen=18.0, co2=24.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-5.16, moisture=60.95, oxygen=98.67, co2=5.04, methane=-26.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 76, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-82.71, moisture=71.0, oxygen=100.0, co2=6.0, methane=-69.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 77, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-35.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-41.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 78, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.16, oxygen=17.97, co2=76.52, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 79, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-43.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 80, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-79.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-63.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 81, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=22.04, moisture=60.95, oxygen=57.87, co2=5.04, methane=-13.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-25.81, moisture=70.95, oxygen=100.0, co2=6.04, methane=-41.08\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 82, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=24.39, moisture=23.19, oxygen=100.0, co2=35.24, methane=-36.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 83, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-66.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-57.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 84, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=45.95, moisture=61.0, oxygen=22.2, co2=5.0, methane=-1.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=28.7, moisture=26.5, oxygen=100.0, co2=32.6, methane=-35.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 85, Total Reward: 0.32\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-88.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 86, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.79, oxygen=15.0, co2=45.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 87, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=10.94, moisture=61.0, oxygen=74.69, co2=5.0, methane=-18.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 88, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=71.0, oxygen=100.0, co2=6.0, methane=-86.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 89, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=12.0, oxygen=18.0, co2=53.2, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-25.55, oxygen=14.97, co2=74.24, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 90, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-15.11, oxygen=15.0, co2=65.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 91, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=11.09, oxygen=15.0, co2=44.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.21, oxygen=18.0, co2=65.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 92, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=-12.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-30.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 93, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=38.35, moisture=61.0, oxygen=33.59, co2=5.0, methane=-5.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-37.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 94, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-4.06, moisture=61.0, oxygen=97.2, co2=5.0, methane=-26.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 95, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-16.91, oxygen=15.0, co2=67.31, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 96, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-61.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-55.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 97, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=43.04, moisture=45.6, oxygen=61.2, co2=17.32, methane=-14.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.94, moisture=45.55, oxygen=61.17, co2=17.36, methane=-14.38\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=37.05, oxygen=17.97, co2=33.16, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=39.23, moisture=38.15, oxygen=83.37, co2=23.28, methane=-21.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 98, Total Reward: 1.19\n",
      "Checking extreme values for chamber: temp=-8.41, moisture=6.79, oxygen=100.0, co2=48.36, methane=-53.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 99, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=84.65, moisture=38.4, oxygen=15.0, co2=23.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=49.89, moisture=49.8, oxygen=81.59, co2=22.96, methane=-19.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 100, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=41.2, moisture=41.9, oxygen=72.3, co2=20.28, methane=-18.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 101, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=-51.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-49.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 102, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=2.59, oxygen=15.0, co2=51.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 103, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-67.0, moisture=-22.5, oxygen=100.0, co2=71.8, methane=-82.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 104, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-47.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-47.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 105, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=3.8899999999999997, oxygen=15.0, co2=50.68, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 106, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-19.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 107, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=42.5, moisture=44.5, oxygen=64.5, co2=18.2, methane=-15.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-34.6, moisture=3.7, oxygen=100.0, co2=59.84, methane=-65.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 108, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=78.2, moisture=42.7, oxygen=15.0, co2=19.64, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-42.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 109, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.09, oxygen=15.0, co2=46.52, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 110, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-99.35499999999999, moisture=61.0, oxygen=100.0, co2=5.0, methane=-74.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 111, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-58.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-53.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 112, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-23.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-36.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 113, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-25.31, oxygen=15.0, co2=74.04, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 114, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-46.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-51.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 115, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=24.59, moisture=23.29, oxygen=100.0, co2=35.15, methane=-36.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 116, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=100.0, moisture=18.29, oxygen=15.0, co2=39.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=80.4, moisture=8.48, oxygen=44.4, co2=47.0, methane=-8.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 117, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-5.5, oxygen=15.0, co2=58.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 118, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=7.39, moisture=14.59, oxygen=100.0, co2=42.12, methane=-45.27\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 119, Total Reward: 1.06\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-5.0, moisture=18.5, oxygen=100.0, co2=48.0, methane=-50.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 120, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=82.85, moisture=56.1, oxygen=18.0, co2=17.92, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-13.21, moisture=4.35, oxygen=100.0, co2=50.32, methane=-55.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 121, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=12.19, moisture=17.09, oxygen=100.0, co2=40.11, methane=-42.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 122, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=-23.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-36.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 123, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=54.95, moisture=58.2, oxygen=15.0, co2=7.24, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-32.46, moisture=58.2, oxygen=100.0, co2=7.24, methane=-42.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 124, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=8.94, moisture=61.0, oxygen=77.69, co2=5.0, methane=-19.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 125, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=36.95, moisture=61.0, oxygen=35.7, co2=5.0, methane=-5.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=98.15, moisture=45.9, oxygen=18.0, co2=26.08, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=18.79, moisture=24.69, oxygen=100.0, co2=34.04, methane=-42.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 126, Total Reward: 0.28\n",
      "Checking extreme values for chamber: temp=89.6, moisture=35.09, oxygen=15.0, co2=25.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-11.21, oxygen=18.0, co2=71.76, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 127, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-20.41, oxygen=15.0, co2=70.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 128, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=85.25, moisture=38.0, oxygen=15.0, co2=23.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-63.81, moisture=-10.91, oxygen=100.0, co2=71.52, methane=-79.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 129, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-37.11, moisture=71.0, oxygen=100.0, co2=6.0, methane=-46.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 130, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=24.19, oxygen=18.0, co2=43.44, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=48.84, moisture=57.35, oxygen=25.77, co2=7.92, methane=-2.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=24.14, oxygen=17.97, co2=43.48, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=89.04, moisture=30.55, oxygen=25.77, co2=29.36, methane=-2.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-27.56, oxygen=17.97, co2=84.84, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 131, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=100.0, moisture=22.9, oxygen=15.0, co2=35.48, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=71.0, oxygen=100.0, co2=6.0, methane=-81.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 132, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.69, oxygen=15.0, co2=46.04, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 133, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-7.61, moisture=7.1899999999999995, oxygen=100.0, co2=48.04, methane=-52.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 134, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.09, oxygen=18.0, co2=55.52, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 135, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-59.81, moisture=-18.91, oxygen=100.0, co2=68.92, methane=-78.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 136, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-12.61, oxygen=18.0, co2=72.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 137, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=77.0, moisture=43.5, oxygen=15.0, co2=19.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.19, oxygen=18.0, co2=55.44, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 138, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=-10.81, moisture=5.59, oxygen=100.0, co2=49.32, methane=-54.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 139, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-83.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 140, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=17.19, moisture=29.54, oxygen=100.0, co2=39.15, methane=-39.39\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 141, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=35.35, moisture=61.0, oxygen=38.09, co2=5.0, methane=-6.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=34.25, moisture=58.8, oxygen=44.69, co2=6.76, methane=-8.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=16.7, moisture=23.69, oxygen=100.0, co2=34.84, methane=-44.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 142, Total Reward: 0.42\n",
      "Checking extreme values for chamber: temp=100.0, moisture=12.79, oxygen=15.0, co2=43.56, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.21, oxygen=18.0, co2=77.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 143, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=37.58, moisture=34.7, oxygen=93.9, co2=26.04, methane=-25.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 144, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=-60.81, moisture=-19.41, oxygen=100.0, co2=69.32, methane=-79.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 145, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=46.75, moisture=61.0, oxygen=21.0, co2=5.0, methane=-1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.8, moisture=43.4, oxygen=100.0, co2=28.08, methane=-25.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 146, Total Reward: 0.18\n",
      "Checking extreme values for chamber: temp=100.0, moisture=18.79, oxygen=15.0, co2=38.76, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=18.73, oxygen=14.97, co2=38.79, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=34.39, moisture=-14.08, oxygen=100.0, co2=65.03, methane=-31.79\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 147, Total Reward: 1.16\n",
      "Checking extreme values for chamber: temp=-59.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-54.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 148, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-69.41, moisture=-13.71, oxygen=100.0, co2=73.76, methane=-82.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 149, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-18.81, moisture=1.5899999999999999, oxygen=100.0, co2=52.52, methane=-58.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 150, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=41.545, moisture=61.0, oxygen=28.79, co2=5.0, methane=-3.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.044999999999995, moisture=50.0, oxygen=28.79, co2=13.8, methane=-3.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.2, moisture=43.05, oxygen=100.0, co2=28.36, methane=-25.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 151, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=2.34, oxygen=17.97, co2=60.92, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 152, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-9.41, moisture=6.29, oxygen=100.0, co2=48.76, methane=-53.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 153, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=38.39, moisture=36.29, oxygen=89.1, co2=24.76, methane=-23.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 154, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-90.71, moisture=71.0, oxygen=100.0, co2=6.0, methane=-73.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 155, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-13.61, moisture=14.19, oxygen=100.0, co2=51.44, methane=-54.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 156, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=15.09, oxygen=15.0, co2=41.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-14.5, oxygen=18.0, co2=74.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 157, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=55.6, moisture=61.2, oxygen=47.4, co2=13.84, methane=-7.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=32.59, moisture=27.25, oxygen=100.0, co2=32.0, methane=-32.68\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 158, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-39.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-48.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 159, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=77.75, moisture=43.0, oxygen=15.0, co2=19.39, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=96.65, moisture=46.9, oxygen=18.0, co2=25.28, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=15.59, moisture=0.79, oxygen=100.0, co2=53.15, methane=-41.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 160, Total Reward: 0.90\n",
      "Checking extreme values for chamber: temp=-19.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 161, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.895, oxygen=15.0, co2=37.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=10.19, oxygen=15.0, co2=45.64, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=75.55, moisture=60.85, oxygen=17.97, co2=14.12, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=32.2, moisture=10.19, oxygen=100.0, co2=45.64, methane=-32.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 162, Total Reward: 1.26\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=7.890000000000001, moisture=71.0, oxygen=96.9, co2=6.0, methane=-24.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 163, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=43.5, moisture=46.5, oxygen=58.5, co2=16.6, methane=-13.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=30.9, moisture=46.5, oxygen=77.4, co2=16.6, methane=-19.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 164, Total Reward: 0.84\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-9.11, oxygen=15.0, co2=61.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 165, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=13.59, oxygen=18.0, co2=51.92, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=13.54, oxygen=17.97, co2=51.96, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-40.41, moisture=-9.31, oxygen=100.0, co2=61.24, methane=-69.16\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 166, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-99.11, moisture=71.0, oxygen=100.0, co2=6.0, methane=-77.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 167, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=40.0, moisture=41.0, oxygen=100.0, co2=30.0, methane=-28.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 168, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-10.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-29.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 169, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=91.7, moisture=50.2, oxygen=18.0, co2=22.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=15.100000000000001, oxygen=18.0, co2=50.72, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=49.09, moisture=58.0, oxygen=23.64, co2=7.4, methane=-1.87\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-3.0, moisture=15.100000000000001, oxygen=100.0, co2=50.72, methane=-49.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 170, Total Reward: 1.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=47.89, moisture=45.8, oxygen=93.6, co2=26.16, methane=-23.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 171, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-30.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-39.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 172, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-12.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-30.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 173, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-40.21, moisture=-9.11, oxygen=100.0, co2=61.08, methane=-69.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 174, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-0.31000000000000005, oxygen=15.0, co2=54.04, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 175, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=8.29, moisture=71.0, oxygen=96.3, co2=6.0, methane=-24.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 176, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=10.59, moisture=16.29, oxygen=100.0, co2=40.76, methane=-43.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 177, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-41.11, moisture=71.0, oxygen=100.0, co2=6.0, methane=-48.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 178, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=4.89, moisture=71.0, oxygen=100.0, co2=6.0, methane=-25.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 179, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-26.41, moisture=-2.21, oxygen=100.0, co2=55.56, methane=-62.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 180, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=47.65, moisture=55.09, oxygen=32.33, co2=9.71, methane=-4.77\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.2, moisture=70.85, oxygen=17.89, co2=6.12, methane=2.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=8.68, oxygen=32.33, co2=46.83, methane=-4.77\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 181, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-59.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-54.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 182, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.19, oxygen=15.0, co2=36.84, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=11.19, moisture=21.19, oxygen=100.0, co2=36.84, methane=-43.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 183, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=53.45, moisture=59.2, oxygen=15.0, co2=6.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=20.895, moisture=71.0, oxygen=77.4, co2=6.0, methane=-17.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 184, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-29.81, moisture=-4.01, oxygen=100.0, co2=57.0, methane=-63.87\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 185, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-63.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-55.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 186, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-76.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 187, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=39.04, moisture=37.59, oxygen=85.2, co2=23.72, methane=-22.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 188, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.64, moisture=51.3, oxygen=77.09, co2=21.76, methane=-17.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 189, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=43.6, moisture=46.7, oxygen=57.9, co2=16.43, methane=-13.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=43.5, moisture=46.65, oxygen=57.87, co2=16.47, methane=-13.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.21, moisture=70.95, oxygen=100.0, co2=6.04, methane=-41.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 190, Total Reward: 0.70\n",
      "Checking extreme values for chamber: temp=52.1, moisture=60.1, oxygen=15.0, co2=5.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=41.5, moisture=71.0, oxygen=46.5, co2=6.0, methane=-7.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-15.2, oxygen=15.0, co2=65.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 191, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-60.81, moisture=-19.41, oxygen=100.0, co2=69.32, methane=-79.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 192, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-14.91, oxygen=15.0, co2=65.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 193, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-14.0, oxygen=15.0, co2=65.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 194, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-44.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 195, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-38.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 196, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-24.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-36.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 197, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-6.96, moisture=60.95, oxygen=100.0, co2=5.04, methane=-27.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 198, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=4.59, oxygen=15.0, co2=50.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 199, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-77.0, moisture=-27.5, oxygen=100.0, co2=75.8, methane=-87.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 200, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=16.69, oxygen=18.0, co2=49.44, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-12.55, oxygen=14.97, co2=63.84, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 201, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.8, moisture=58.8, oxygen=18.0, co2=15.76, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.7, moisture=58.75, oxygen=17.97, co2=15.8, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-33.6, moisture=-5.9, oxygen=100.0, co2=58.52, methane=-65.76\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 202, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-24.21, oxygen=15.0, co2=73.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 203, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-68.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-58.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 204, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-26.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-41.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 205, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=91.4, moisture=50.4, oxygen=18.0, co2=22.48, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-9.81, moisture=6.04, oxygen=100.0, co2=48.96, methane=-53.88\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 206, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-13.21, oxygen=15.0, co2=64.36, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 207, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=20.395, oxygen=15.0, co2=37.48, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=43.2, moisture=-8.015, oxygen=100.0, co2=60.2, methane=-27.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 208, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-24.61, moisture=8.69, oxygen=100.0, co2=55.84, methane=-60.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 209, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-94.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-71.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 210, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=7.39, moisture=14.69, oxygen=100.0, co2=42.04, methane=-45.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 211, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-78.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 212, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=60.8, moisture=54.3, oxygen=15.0, co2=10.36, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-74.41, moisture=54.3, oxygen=100.0, co2=10.36, methane=-66.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 213, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=13.0, moisture=17.5, oxygen=100.0, co2=39.8, methane=-42.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 214, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.395, oxygen=15.0, co2=36.68, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-74.61, moisture=-16.31, oxygen=100.0, co2=75.84, methane=-85.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 215, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.71, oxygen=15.0, co2=67.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 216, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=48.95, moisture=61.0, oxygen=17.7, co2=5.0, methane=0.09\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-93.9, moisture=71.0, oxygen=100.0, co2=6.0, methane=-75.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 217, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=0.75, moisture=61.0, oxygen=90.0, co2=5.0, methane=-24.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 218, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-85.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-67.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 219, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-0.61, moisture=10.69, oxygen=100.0, co2=45.24, methane=-49.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 220, Total Reward: 0.10\n",
      "Checking extreme values for chamber: temp=50.2, moisture=59.9, oxygen=18.3, co2=5.88, methane=-0.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.0, oxygen=18.0, co2=77.2, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 221, Total Reward: 0.18\n",
      "Checking extreme values for chamber: temp=-41.21, moisture=-9.61, oxygen=100.0, co2=61.48, methane=-69.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 222, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-9.21, moisture=6.39, oxygen=100.0, co2=48.68, methane=-53.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 223, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=26.69, moisture=71.0, oxygen=68.69, co2=6.0, methane=-14.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-13.81, moisture=14.09, oxygen=100.0, co2=51.52, methane=-71.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 224, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=10.54, moisture=61.0, oxygen=75.3, co2=5.0, methane=-19.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 225, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-26.61, moisture=-2.31, oxygen=100.0, co2=55.64, methane=-62.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 226, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=39.29, oxygen=18.0, co2=31.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-26.96, oxygen=14.97, co2=75.36, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 227, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-25.61, moisture=-1.81, oxygen=100.0, co2=55.24, methane=-61.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 228, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-33.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-40.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 229, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=42.15, moisture=61.0, oxygen=27.9, co2=5.0, methane=-3.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=36.19, moisture=39.09, oxygen=100.0, co2=31.52, methane=-29.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 230, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-76.21, moisture=-27.11, oxygen=100.0, co2=75.48, methane=-87.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 231, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-23.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-36.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 232, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=27.9, moisture=71.0, oxygen=66.9, co2=6.0, methane=-14.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=60.95, oxygen=100.0, co2=5.04, methane=-77.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 233, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-77.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-62.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 234, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-3.46, moisture=61.0, oxygen=96.3, co2=5.0, methane=-26.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 235, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=6.79, moisture=14.29, oxygen=100.0, co2=42.36, methane=-45.56\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 236, Total Reward: 1.06\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=67.0, moisture=50.05, oxygen=14.97, co2=13.76, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=5.25, oxygen=17.97, co2=58.6, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 237, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-75.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 238, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=10.79, moisture=16.39, oxygen=100.0, co2=40.68, methane=-43.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 239, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=42.95, moisture=61.0, oxygen=26.7, co2=5.0, methane=-2.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.59, oxygen=26.7, co2=38.11, methane=-2.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.14999999999999997, oxygen=17.97, co2=62.68, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 240, Total Reward: 0.10\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-62.7, moisture=71.0, oxygen=100.0, co2=6.0, methane=-59.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 241, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-61.81, moisture=-19.91, oxygen=100.0, co2=69.72, methane=-79.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 242, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-77.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 243, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.8899999999999999, oxygen=15.0, co2=53.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 244, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-5.3, moisture=71.0, oxygen=100.0, co2=6.0, methane=-30.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 245, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=38.95, moisture=61.0, oxygen=32.7, co2=5.0, methane=-4.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-33.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-45.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 246, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-45.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-47.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 247, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-25.41, moisture=-1.71, oxygen=100.0, co2=55.16, methane=-61.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 248, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-54.86, moisture=60.9, oxygen=100.0, co2=5.08, methane=-51.66\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 249, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-2.41, oxygen=18.0, co2=64.72, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 250, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-79.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-67.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 251, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-99.60499999999999, moisture=71.0, oxygen=100.0, co2=6.0, methane=-78.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 252, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.2, moisture=64.55, oxygen=37.17, co2=11.16, methane=-4.39\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.98, moisture=49.8, oxygen=48.23, co2=13.96, methane=-10.07\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.0, moisture=1.04, oxygen=100.0, co2=61.96, methane=-67.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 253, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-0.61, moisture=10.69, oxygen=100.0, co2=45.24, methane=-49.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 254, Total Reward: 0.10\n",
      "Checking extreme values for chamber: temp=25.2, moisture=23.6, oxygen=100.0, co2=34.92, methane=-36.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 255, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.35, oxygen=14.97, co2=36.72, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=5.15, oxygen=17.97, co2=58.68, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 256, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.2, moisture=64.4, oxygen=37.79, co2=11.28, methane=-4.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-61.96, moisture=60.95, oxygen=100.0, co2=5.04, methane=-55.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 257, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-38.0, moisture=-8.0, oxygen=100.0, co2=60.2, methane=-68.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 258, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=95.75, moisture=31.0, oxygen=15.0, co2=29.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.65, moisture=58.9, oxygen=18.0, co2=15.68, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=95.65, moisture=30.95, oxygen=14.97, co2=29.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.55, moisture=58.85, oxygen=17.97, co2=15.72, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=95.55, moisture=30.9, oxygen=14.94, co2=29.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-31.060000000000002, oxygen=17.97, co2=87.64, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 259, Total Reward: 2.28\n",
      "Checking extreme values for chamber: temp=91.85, moisture=33.59, oxygen=15.0, co2=26.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=44.0, oxygen=18.0, co2=27.6, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=2.89, oxygen=15.0, co2=51.48, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 260, Total Reward: 1.17\n",
      "Checking extreme values for chamber: temp=-0.41, moisture=10.79, oxygen=100.0, co2=45.16, methane=-49.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 261, Total Reward: 0.10\n",
      "Checking extreme values for chamber: temp=-73.41, moisture=-25.71, oxygen=100.0, co2=74.36, methane=-85.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 262, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-86.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 263, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=39.39, moisture=38.29, oxygen=83.1, co2=23.16, methane=-21.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 264, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=37.79, moisture=39.9, oxygen=100.0, co2=30.88, methane=-29.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 265, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=47.75, moisture=55.0, oxygen=33.0, co2=9.8, methane=-5.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-12.61, oxygen=18.0, co2=72.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 266, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-56.41, moisture=-7.210000000000001, oxygen=100.0, co2=68.56, methane=-76.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 267, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=94.4, moisture=48.4, oxygen=18.0, co2=24.08, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-16.41, moisture=2.75, oxygen=100.0, co2=51.6, methane=-57.18\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 268, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=63.8, moisture=52.3, oxygen=15.0, co2=11.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.69, oxygen=18.0, co2=47.04, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=52.3, oxygen=100.0, co2=11.96, methane=-87.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 269, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=90.35, moisture=34.59, oxygen=15.0, co2=26.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=22.5, oxygen=18.0, co2=44.8, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=9.74, moisture=34.59, oxygen=100.0, co2=26.12, methane=-39.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 270, Total Reward: 1.25\n",
      "Checking extreme values for chamber: temp=-45.6, moisture=-11.8, oxygen=100.0, co2=63.24, methane=-71.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 271, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.59, oxygen=18.0, co2=55.12, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 272, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=6.09, oxygen=15.0, co2=48.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 273, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.3, moisture=71.0, oxygen=21.3, co2=6.0, methane=0.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.3499999999999996, oxygen=14.97, co2=56.48, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 274, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-65.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-57.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 275, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.55, moisture=54.35, oxygen=14.97, co2=10.32, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=25.2, moisture=16.95, oxygen=100.0, co2=40.24, methane=-36.38\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 276, Total Reward: 1.06\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-86.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 277, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-48.6, moisture=-13.3, oxygen=100.0, co2=64.44, methane=-73.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 278, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=36.54, moisture=61.0, oxygen=36.29, co2=5.0, methane=-6.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-48.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-52.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 279, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-52.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-50.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 280, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-72.0, moisture=70.95, oxygen=100.0, co2=6.04, methane=-64.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 281, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.91, oxygen=15.0, co2=68.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 282, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-4.11, oxygen=15.0, co2=57.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 283, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-61.0, moisture=-19.605, oxygen=100.0, co2=69.48, methane=-79.46\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 284, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.59, oxygen=15.0, co2=46.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 285, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=36.75, moisture=61.0, oxygen=36.0, co2=5.0, methane=-6.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-15.3, moisture=71.0, oxygen=100.0, co2=6.0, methane=-35.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 286, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=48.39, moisture=46.8, oxygen=90.6, co2=25.36, methane=-22.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 287, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-98.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-73.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 288, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=23.0, moisture=22.5, oxygen=100.0, co2=35.79, methane=-37.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 289, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-61.81, moisture=-9.96, oxygen=100.0, co2=70.76, methane=-78.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 290, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-8.5, oxygen=15.0, co2=60.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 291, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-86.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 292, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-38.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 293, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-39.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 294, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.0, moisture=70.0, oxygen=21.0, co2=6.8, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-48.81, moisture=-13.46, oxygen=100.0, co2=64.56, methane=-73.39\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 295, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-45.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 296, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=66.5, moisture=50.5, oxygen=15.0, co2=13.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=20.5, oxygen=18.0, co2=46.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.19999999999999, moisture=28.6, oxygen=15.0, co2=30.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=20.45, oxygen=17.97, co2=46.44, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.1, moisture=28.55, oxygen=14.97, co2=30.96, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-39.5, moisture=20.45, oxygen=100.0, co2=46.44, methane=-67.69\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 297, Total Reward: 1.23\n",
      "Checking extreme values for chamber: temp=-57.61, moisture=-17.81, oxygen=100.0, co2=68.03, methane=-77.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 298, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-54.61, moisture=-16.31, oxygen=100.0, co2=66.84, methane=-76.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 299, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=32.39, moisture=27.19, oxygen=100.0, co2=32.04, methane=-32.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 300, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-75.0, moisture=-26.5, oxygen=100.0, co2=75.0, methane=-86.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 301, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-23.01, moisture=70.95, oxygen=100.0, co2=6.04, methane=-39.68\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 302, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=35.79, moisture=38.9, oxygen=100.0, co2=31.68, methane=-30.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 303, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-9.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-33.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 304, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=43.0, moisture=45.5, oxygen=61.5, co2=17.39, methane=-14.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.9, moisture=45.45, oxygen=61.47, co2=17.43, methane=-14.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-21.6, moisture=70.95, oxygen=100.0, co2=6.04, methane=-38.98\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 305, Total Reward: 0.70\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=13.09, moisture=71.0, oxygen=89.1, co2=6.0, methane=-21.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 306, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=26.79, moisture=34.4, oxygen=100.0, co2=35.28, methane=-34.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 307, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=19.59, moisture=20.79, oxygen=100.0, co2=37.16, methane=-39.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 308, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-1.21, oxygen=15.0, co2=54.76, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 309, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=54.65, moisture=58.4, oxygen=15.0, co2=7.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=13.0, oxygen=18.0, co2=52.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=54.55, moisture=58.35, oxygen=14.97, co2=7.12, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-22.4, oxygen=18.0, co2=80.72, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 310, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-11.46, oxygen=14.97, co2=62.96, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 311, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-72.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-60.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 312, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-51.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-50.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 313, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.09, oxygen=18.0, co2=41.12, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-47.96, moisture=60.95, oxygen=100.0, co2=5.04, methane=-48.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 314, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=3.09, oxygen=15.0, co2=51.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 315, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-43.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 316, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=25.5, moisture=71.0, oxygen=70.5, co2=6.0, methane=-15.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 317, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-27.21, moisture=-2.61, oxygen=100.0, co2=55.88, methane=-62.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 318, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=59.35, moisture=68.7, oxygen=24.9, co2=7.84, methane=-0.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=78.09, moisture=56.2, oxygen=24.9, co2=17.84, methane=-0.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.45, moisture=60.85, oxygen=14.91, co2=5.12, methane=1.06\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=77.99, moisture=56.15, oxygen=24.86, co2=17.88, methane=-0.29\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=31.450000000000003, moisture=60.85, oxygen=43.41, co2=5.12, methane=-8.44\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-30.66, oxygen=24.86, co2=87.32, methane=-0.29\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 319, Total Reward: 1.37\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=49.45, moisture=60.95, oxygen=16.77, co2=5.04, methane=0.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-2.35, oxygen=17.97, co2=64.68, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 320, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=25.39, moisture=23.69, oxygen=100.0, co2=34.84, methane=-36.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 321, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=47.65, moisture=54.95, oxygen=32.97, co2=9.84, methane=-4.99\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=18.25, oxygen=17.97, co2=48.2, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-38.96, moisture=54.95, oxygen=100.0, co2=9.84, methane=-48.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 322, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-34.81, moisture=-6.41, oxygen=100.0, co2=58.92, methane=-66.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 323, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-4.41, oxygen=15.0, co2=57.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 324, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-36.0, moisture=-7.0, oxygen=100.0, co2=59.4, methane=-67.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 325, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=59.4, moisture=68.8, oxygen=24.6, co2=7.76, methane=-0.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.59, oxygen=24.6, co2=45.52, methane=-0.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=43.34, moisture=46.5, oxygen=58.13, co2=16.6, methane=-13.36\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=21.54, oxygen=24.57, co2=45.56, methane=-0.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=19.0, moisture=6.0, oxygen=100.0, co2=49.0, methane=-53.86\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 326, Total Reward: 1.31\n",
      "Checking extreme values for chamber: temp=-99.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-74.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 327, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=99.67500000000001, moisture=28.1, oxygen=15.0, co2=31.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=14.4, oxygen=15.0, co2=42.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.25, oxygen=17.97, co2=77.4, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 328, Total Reward: 0.92\n",
      "Checking extreme values for chamber: temp=61.25, moisture=54.0, oxygen=15.0, co2=10.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-5.21, oxygen=18.0, co2=66.96, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 329, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-72.56, moisture=60.95, oxygen=100.0, co2=5.04, methane=-60.58\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 330, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=56.6, moisture=57.1, oxygen=15.0, co2=8.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=92.3, moisture=49.8, oxygen=18.0, co2=22.96, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=56.5, moisture=57.05, oxygen=14.97, co2=8.15, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-32.61, oxygen=18.0, co2=88.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 331, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=51.25, moisture=52.5, oxygen=73.5, co2=20.8, methane=-16.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 332, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-57.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-53.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 333, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=0.54, moisture=61.0, oxygen=90.3, co2=5.0, methane=-24.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 334, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=19.59, moisture=30.79, oxygen=100.0, co2=38.16, methane=-38.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 335, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-15.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-32.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 336, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-78.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-63.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 337, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=45.0, moisture=49.5, oxygen=49.5, co2=14.2, methane=-10.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=96.94, moisture=46.7, oxygen=18.0, co2=25.44, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.9, moisture=49.45, oxygen=49.47, co2=14.23, methane=-10.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.0, oxygen=18.0, co2=46.0, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-25.35, oxygen=49.47, co2=74.07, methane=-10.48\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 338, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=27.6, oxygen=15.0, co2=31.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-12.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-34.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 339, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-58.11, moisture=71.0, oxygen=100.0, co2=6.0, methane=-57.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 340, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-80.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 341, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=26.5, oxygen=15.0, co2=32.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=26.45, oxygen=14.97, co2=32.64, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=9.35, oxygen=17.97, co2=55.32, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 342, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=-71.81, moisture=-24.91, oxygen=100.0, co2=73.72, methane=-84.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 343, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=32.9, moisture=71.0, oxygen=59.4, co2=6.0, methane=-11.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-12.66, oxygen=14.97, co2=63.92, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 344, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=53.2, moisture=59.25, oxygen=14.97, co2=6.4, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-8.41, moisture=16.75, oxygen=100.0, co2=49.4, methane=-52.18\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 345, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-13.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-35.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 346, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-0.30000000000000004, oxygen=18.0, co2=63.04, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 347, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-62.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-55.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 348, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=64.84, moisture=51.6, oxygen=15.0, co2=12.52, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-41.21, moisture=0.38999999999999996, oxygen=100.0, co2=62.48, methane=-68.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 349, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=67.84, moisture=66.09, oxygen=18.0, co2=9.92, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.04, oxygen=14.97, co2=38.56, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-6.02, oxygen=18.0, co2=67.59, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 350, Total Reward: 0.92\n",
      "Checking extreme values for chamber: temp=3.54, moisture=61.0, oxygen=85.8, co2=5.0, methane=-22.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 351, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=27.1, moisture=71.0, oxygen=68.09, co2=6.0, methane=-14.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-19.46, oxygen=14.97, co2=69.36, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 352, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=1.3399999999999999, moisture=61.0, oxygen=89.1, co2=5.0, methane=-23.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 353, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-83.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 354, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.3, moisture=71.0, oxygen=42.3, co2=6.0, methane=-6.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-85.95, moisture=60.95, oxygen=100.0, co2=5.04, methane=-67.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 355, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-22.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-35.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 356, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-43.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 357, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-83.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 358, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=47.5, moisture=54.5, oxygen=34.5, co2=10.19, methane=-5.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=29.69, oxygen=18.0, co2=39.04, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=37.95, moisture=35.4, oxygen=91.8, co2=25.47, methane=-24.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 359, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.0, oxygen=15.0, co2=56.2, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 360, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-10.3, moisture=71.0, oxygen=100.0, co2=6.0, methane=-33.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 361, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-48.81, moisture=-13.41, oxygen=100.0, co2=64.52, methane=-73.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 362, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=42.65, moisture=44.8, oxygen=63.6, co2=17.96, methane=-15.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=97.85, moisture=46.09, oxygen=18.0, co2=25.92, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=44.8, oxygen=100.0, co2=17.96, methane=-89.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 363, Total Reward: 0.70\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.81, oxygen=15.0, co2=68.03, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 364, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-65.61, moisture=-21.81, oxygen=100.0, co2=71.23, methane=-81.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 365, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=53.15, moisture=59.4, oxygen=15.0, co2=6.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-9.11, oxygen=18.0, co2=70.08, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 366, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-3.5, oxygen=15.0, co2=56.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 367, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=6.34, moisture=61.0, oxygen=81.59, co2=5.0, methane=-21.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 368, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=0.5, oxygen=18.0, co2=62.4, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 369, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-26.41, oxygen=15.0, co2=74.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 370, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-24.0, moisture=9.0, oxygen=100.0, co2=55.6, methane=-60.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 371, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=3.84, moisture=60.95, oxygen=85.17, co2=5.04, methane=-22.39\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 372, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=40.2, moisture=39.9, oxygen=78.3, co2=21.88, methane=-20.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 373, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=69.2, moisture=48.7, oxygen=15.0, co2=14.84, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-10.41, moisture=-6.5, oxygen=100.0, co2=59.0, methane=-54.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 374, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-18.41, oxygen=15.0, co2=68.52, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 375, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=95.75, moisture=31.0, oxygen=15.0, co2=29.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=82.095, moisture=56.6, oxygen=18.0, co2=17.52, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=95.65, moisture=30.95, oxygen=14.97, co2=29.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-27.4, oxygen=18.0, co2=84.72, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 376, Total Reward: 1.52\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=12.89, oxygen=18.0, co2=52.48, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-66.96, moisture=60.95, oxygen=100.0, co2=5.04, methane=-57.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 377, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-42.0, moisture=-10.0, oxygen=100.0, co2=61.8, methane=-70.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 378, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-34.41, moisture=-6.21, oxygen=100.0, co2=58.76, methane=-66.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 379, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=24.59, moisture=23.29, oxygen=100.0, co2=35.15, methane=-36.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 380, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=100.0, moisture=19.0, oxygen=15.0, co2=38.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=32.4, oxygen=18.0, co2=36.87, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.0, moisture=-44.5, oxygen=100.0, co2=89.4, methane=-62.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 381, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=-25.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-37.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 382, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-6.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-27.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 383, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-7.21, moisture=7.390000000000001, oxygen=100.0, co2=47.88, methane=-52.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 384, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-37.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-43.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 385, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.21, oxygen=15.0, co2=61.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 386, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-4.21, moisture=8.89, oxygen=100.0, co2=46.68, methane=-51.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 387, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-42.21, moisture=-10.11, oxygen=100.0, co2=61.88, methane=-70.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 388, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-24.11, oxygen=15.0, co2=73.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 389, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-5.11, oxygen=15.0, co2=57.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 390, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-10.61, oxygen=15.0, co2=62.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 391, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-54.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-51.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 392, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-8.91, oxygen=15.0, co2=60.92, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 393, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=51.45, moisture=52.9, oxygen=72.3, co2=20.48, methane=-16.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 394, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-44.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 395, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-79.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-64.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 396, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-40.455, moisture=61.0, oxygen=100.0, co2=5.0, methane=-44.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 397, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-88.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-68.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 398, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=60.9, oxygen=100.0, co2=5.08, methane=-83.46\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 399, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=77.15, moisture=59.9, oxygen=18.0, co2=14.88, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=36.99, moisture=33.65, oxygen=96.86, co2=26.88, methane=-26.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 400, Total Reward: 0.90\n",
      "Checking extreme values for chamber: temp=-95.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-72.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 401, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.109999999999999, oxygen=15.0, co2=59.48, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 402, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=16.14, moisture=61.0, oxygen=66.9, co2=5.0, methane=-16.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-36.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-46.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 403, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-54.0, moisture=-6.0, oxygen=100.0, co2=67.59, methane=-75.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 404, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=10.5, oxygen=15.0, co2=45.4, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-72.21, moisture=-15.11, oxygen=100.0, co2=74.88, methane=-84.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 405, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-23.31, moisture=71.0, oxygen=100.0, co2=6.0, methane=-39.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 406, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=55.79, moisture=61.6, oxygen=46.2, co2=13.52, methane=-7.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.55, moisture=60.9, oxygen=14.94, co2=5.08, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.74, moisture=60.3, oxygen=46.2, co2=14.55, methane=-7.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=38.94, moisture=60.9, oxygen=32.33, co2=5.08, methane=-4.77\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=6.19, oxygen=46.2, co2=57.83, methane=-7.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 407, Total Reward: 0.96\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-70.61, moisture=-14.31, oxygen=100.0, co2=74.23, methane=-83.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 408, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-54.41, moisture=-16.21, oxygen=100.0, co2=66.75, methane=-76.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 409, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-85.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 410, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-80.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 411, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-51.0, moisture=-14.5, oxygen=100.0, co2=65.4, methane=-74.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 412, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=47.25, moisture=54.0, oxygen=36.0, co2=10.6, methane=-6.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=6.5, oxygen=18.0, co2=57.6, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 413, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=8.29, oxygen=15.0, co2=47.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 414, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-80.85, moisture=61.0, oxygen=100.0, co2=5.0, methane=-64.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 415, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=49.75, moisture=61.0, oxygen=16.5, co2=5.0, methane=0.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-15.21, moisture=13.39, oxygen=100.0, co2=52.08, methane=-55.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 416, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-61.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-55.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 417, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-82.06, moisture=61.0, oxygen=100.0, co2=5.0, methane=-65.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 418, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-1.6099999999999999, oxygen=15.0, co2=55.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 419, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=39.95, moisture=61.0, oxygen=31.2, co2=5.0, methane=-4.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=1.29, oxygen=18.0, co2=61.76, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 420, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=36.95, moisture=33.4, oxygen=97.8, co2=27.08, methane=-26.6\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 421, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-7.8100000000000005, oxygen=18.0, co2=69.03, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 422, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-45.41, moisture=-11.71, oxygen=100.0, co2=63.16, methane=-71.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 423, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=42.15, moisture=61.0, oxygen=27.9, co2=5.0, methane=-3.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=87.15, moisture=31.0, oxygen=27.9, co2=29.0, methane=-3.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=42.0, moisture=70.95, oxygen=45.56, co2=6.04, methane=-7.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-21.6, oxygen=27.9, co2=71.08, methane=-3.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 424, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=100.0, moisture=6.69, oxygen=15.0, co2=48.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 425, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-17.71, oxygen=15.0, co2=67.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 426, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-5.66, moisture=61.0, oxygen=99.6, co2=5.0, methane=-27.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 427, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-43.45, moisture=61.0, oxygen=100.0, co2=5.0, methane=-46.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 428, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=80.3, moisture=57.8, oxygen=18.0, co2=16.56, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-27.96, oxygen=14.97, co2=76.16, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 429, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=48.5, moisture=56.5, oxygen=28.5, co2=8.6, methane=-3.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=7.5, oxygen=18.0, co2=56.8, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 430, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-13.41, moisture=4.29, oxygen=100.0, co2=50.36, methane=-55.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 431, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=18.29, oxygen=15.0, co2=39.16, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=85.4, moisture=54.4, oxygen=18.0, co2=19.28, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-52.81, moisture=-58.12, oxygen=100.0, co2=100.28, methane=-75.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 432, Total Reward: 0.51\n",
      "Checking extreme values for chamber: temp=67.84, moisture=49.6, oxygen=15.0, co2=14.12, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-30.6, moisture=-15.7, oxygen=100.0, co2=66.36, methane=-64.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 433, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-22.41, oxygen=15.0, co2=71.72, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 434, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=67.4, moisture=49.9, oxygen=15.0, co2=13.88, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=98.6, moisture=29.1, oxygen=15.0, co2=30.52, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-8.75, oxygen=17.97, co2=69.8, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 435, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=43.89, moisture=47.3, oxygen=56.1, co2=15.96, methane=-12.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=37.59, moisture=39.79, oxygen=100.0, co2=30.96, methane=-29.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 436, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=-46.0, moisture=-12.0, oxygen=100.0, co2=63.4, methane=-72.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 437, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-13.5, oxygen=15.0, co2=64.59, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 438, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=69.95, moisture=48.2, oxygen=15.0, co2=15.24, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=71.0, oxygen=100.0, co2=6.0, methane=-79.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 439, Total Reward: 0.76\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-9.55, oxygen=14.97, co2=61.44, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 440, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=44.2, moisture=47.9, oxygen=54.3, co2=15.48, methane=-12.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.2, moisture=50.4, oxygen=79.8, co2=22.48, methane=-18.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 441, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=71.9, moisture=46.9, oxygen=15.0, co2=16.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=83.45, moisture=39.19, oxygen=15.0, co2=22.44, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=7.19, moisture=24.54, oxygen=100.0, co2=43.16, methane=-44.38\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 442, Total Reward: 1.52\n",
      "Checking extreme values for chamber: temp=14.0, moisture=18.0, oxygen=100.0, co2=39.4, methane=-42.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 443, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=23.79, oxygen=18.0, co2=43.76, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=38.99, moisture=37.65, oxygen=84.86, co2=23.68, methane=-22.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 444, Total Reward: 0.90\n",
      "Checking extreme values for chamber: temp=100.0, moisture=21.9, oxygen=15.0, co2=36.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=21.85, oxygen=14.97, co2=36.32, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.3, moisture=70.9, oxygen=17.93, co2=6.08, methane=2.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-49.95, oxygen=14.97, co2=93.76, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 445, Total Reward: 1.23\n",
      "Checking extreme values for chamber: temp=-7.460000000000001, moisture=61.0, oxygen=100.0, co2=5.0, methane=-28.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 446, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-73.25, moisture=61.0, oxygen=100.0, co2=5.0, methane=-61.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 447, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=1.09, moisture=71.0, oxygen=100.0, co2=6.0, methane=-27.71\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 448, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=52.7, moisture=55.4, oxygen=64.8, co2=18.48, methane=-13.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-0.25, oxygen=14.97, co2=54.0, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 449, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=38.33, moisture=36.2, oxygen=89.4, co2=24.84, methane=-23.8\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 450, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-27.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-42.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 451, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.9, moisture=71.0, oxygen=20.39, co2=6.0, methane=1.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=24.04, moisture=60.95, oxygen=54.87, co2=5.04, methane=-12.28\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.8, moisture=70.95, oxygen=20.36, co2=6.04, methane=1.22\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=23.94, moisture=60.9, oxygen=54.84, co2=5.08, methane=-12.26\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.7, moisture=70.9, oxygen=20.32, co2=6.08, methane=1.24\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=23.84, moisture=60.85, oxygen=54.81, co2=5.12, methane=-12.24\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.6, moisture=70.85, oxygen=20.29, co2=6.12, methane=1.26\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=60.85, oxygen=100.0, co2=5.12, methane=-97.44\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 452, Total Reward: 0.83\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-84.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 453, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=39.29, moisture=38.09, oxygen=83.7, co2=23.32, methane=-21.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 454, Total Reward: 0.49\n",
      "Checking extreme values for chamber: temp=-11.86, moisture=61.0, oxygen=100.0, co2=5.0, methane=-30.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 455, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=31.700000000000003, moisture=71.0, oxygen=61.2, co2=6.0, methane=-12.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=60.95, oxygen=100.0, co2=5.04, methane=-83.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 456, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.4, moisture=64.8, oxygen=36.59, co2=10.96, methane=-4.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=76.45, moisture=43.75, oxygen=14.97, co2=18.8, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.3, moisture=64.75, oxygen=36.56, co2=11.0, methane=-4.19\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=76.35, moisture=43.7, oxygen=14.94, co2=18.84, methane=1.04\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.2, moisture=64.7, oxygen=36.53, co2=11.04, methane=-4.18\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=61.74, moisture=43.7, oxygen=36.83, co2=18.84, methane=-6.27\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=84.65, moisture=46.4, oxygen=36.53, co2=25.68, methane=-4.18\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=61.64, moisture=43.65, oxygen=36.79, co2=18.88, methane=-6.25\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=83.25, moisture=46.4, oxygen=38.63, co2=25.68, methane=-4.88\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-9.66, oxygen=36.79, co2=61.52, methane=-6.25\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 457, Total Reward: 2.63\n",
      "Checking extreme values for chamber: temp=100.0, moisture=5.89, oxygen=15.0, co2=49.08, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 458, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=1.0, moisture=11.5, oxygen=100.0, co2=44.6, methane=-48.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 459, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-87.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 460, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-83.65, moisture=61.0, oxygen=100.0, co2=5.0, methane=-66.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 461, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=2.29, oxygen=15.0, co2=51.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 462, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=48.05, moisture=55.6, oxygen=31.2, co2=9.32, methane=-4.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-22.11, moisture=71.0, oxygen=100.0, co2=6.0, methane=-39.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 463, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=3.09, oxygen=15.0, co2=51.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 464, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=80.0, moisture=41.5, oxygen=15.0, co2=20.6, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-6.91, oxygen=15.0, co2=59.32, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 465, Total Reward: 1.17\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=57.7, moisture=65.4, oxygen=34.79, co2=10.48, methane=-3.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=49.7, moisture=59.05, oxygen=20.67, co2=6.56, methane=-0.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-39.81, moisture=-4.5, oxygen=100.0, co2=66.4, methane=-73.52\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 466, Total Reward: 0.59\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-79.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 467, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=45.04, moisture=49.6, oxygen=49.2, co2=14.12, methane=-10.4\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=21.79, moisture=31.9, oxygen=100.0, co2=37.28, methane=-37.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 468, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=16.39, moisture=19.19, oxygen=100.0, co2=38.44, methane=-40.81\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 469, Total Reward: 0.24\n",
      "Checking extreme values for chamber: temp=-25.05, moisture=61.0, oxygen=100.0, co2=5.0, methane=-36.9\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 470, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-63.81, moisture=-10.91, oxygen=100.0, co2=71.52, methane=-79.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 471, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=55.75, moisture=61.5, oxygen=46.5, co2=13.6, methane=-7.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=16.35, oxygen=14.97, co2=40.72, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=48.75, moisture=47.5, oxygen=88.5, co2=24.8, methane=-21.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 472, Total Reward: 0.92\n",
      "Checking extreme values for chamber: temp=-19.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-34.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 473, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=44.95, moisture=61.0, oxygen=23.7, co2=5.0, methane=-1.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=55.0, moisture=60.0, oxygen=51.0, co2=14.8, methane=-9.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=44.85, moisture=60.95, oxygen=23.67, co2=5.04, methane=-1.89\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-53.2, moisture=60.0, oxygen=100.0, co2=14.8, methane=-63.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 474, Total Reward: 0.36\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=29.29, oxygen=18.0, co2=39.36, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=50.3, moisture=60.25, oxygen=17.07, co2=5.6, methane=0.31\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=73.4, moisture=29.29, oxygen=57.9, co2=39.36, methane=-11.3\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-18.21, moisture=1.1400000000000001, oxygen=100.0, co2=52.88, methane=-58.79\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 475, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-8.0, moisture=17.0, oxygen=100.0, co2=49.2, methane=-52.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 476, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-23.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-40.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 477, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=17.54, moisture=61.0, oxygen=64.8, co2=5.0, methane=-15.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-86.51\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 478, Total Reward: 0.14\n",
      "Checking extreme values for chamber: temp=41.2, moisture=41.9, oxygen=72.3, co2=20.28, methane=-18.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 479, Total Reward: 0.35\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-25.91, oxygen=15.0, co2=74.52, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 480, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-17.46, moisture=61.0, oxygen=100.0, co2=5.0, methane=-33.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 481, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-24.5, moisture=71.0, oxygen=100.0, co2=6.0, methane=-40.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 482, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=-67.0, moisture=-22.5, oxygen=100.0, co2=71.8, methane=-82.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 483, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-26.41, moisture=-2.21, oxygen=100.0, co2=55.56, methane=-62.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 484, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-9.61, moisture=6.14, oxygen=100.0, co2=48.88, methane=-53.78\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 485, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=49.65, moisture=58.8, oxygen=21.6, co2=6.76, methane=-1.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-88.9, moisture=71.0, oxygen=100.0, co2=6.0, methane=-72.7\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 486, Total Reward: 0.18\n",
      "Checking extreme values for chamber: temp=-65.66, moisture=61.0, oxygen=100.0, co2=5.0, methane=-57.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 487, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=100.0, moisture=23.9, oxygen=15.0, co2=34.68, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=60.4, moisture=70.95, oxygen=17.97, co2=6.04, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-37.71, oxygen=15.0, co2=83.96, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 488, Total Reward: 0.82\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=17.79, moisture=29.9, oxygen=100.0, co2=38.88, methane=-39.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 489, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-28.21, moisture=6.89, oxygen=100.0, co2=57.28, methane=-62.11\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 490, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=98.15, moisture=29.4, oxygen=15.0, co2=30.28, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-9.91, moisture=71.0, oxygen=100.0, co2=6.0, methane=-33.21\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 491, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=25.0, oxygen=18.0, co2=42.8, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=10.04, oxygen=14.97, co2=45.76, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.9, moisture=24.95, oxygen=17.97, co2=42.84, methane=2.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-44.06, oxygen=14.97, co2=89.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 492, Total Reward: 1.33\n",
      "Checking extreme values for chamber: temp=-100.0, moisture=61.0, oxygen=100.0, co2=5.0, methane=-78.41\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 493, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-78.21, moisture=-28.11, oxygen=100.0, co2=76.28, methane=-88.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 494, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-74.41, moisture=-26.21, oxygen=100.0, co2=74.76, methane=-86.2\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 495, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=-39.81, moisture=-8.91, oxygen=100.0, co2=60.92, methane=-68.91\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 496, Total Reward: 0.00\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=99.19, moisture=45.2, oxygen=18.0, co2=26.64, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=15.44, moisture=60.95, oxygen=67.77, co2=5.04, methane=-16.59\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-57.21, moisture=-33.41, oxygen=100.0, co2=89.52, methane=-76.61\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 497, Total Reward: 0.55\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=-31.0, moisture=5.5, oxygen=100.0, co2=58.4, methane=-63.5\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 498, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=-12.11, oxygen=18.0, co2=72.48, methane=2.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 499, Total Reward: 0.41\n",
      "Checking extreme values for chamber: temp=50.65, moisture=60.95, oxygen=14.97, co2=5.04, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=58.5, moisture=71.0, oxygen=21.0, co2=6.0, methane=1.0\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=100.0, moisture=25.15, oxygen=14.97, co2=33.68, methane=1.02\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Checking extreme values for chamber: temp=19.79, moisture=30.9, oxygen=100.0, co2=38.08, methane=-39.1\n",
      "Thresholds: temperature=(0, 100), moisture=(10, 100), oxygen=(5, 70), co2=(0, 70), methane=(0, 30)\n",
      "Episode 500, Total Reward: 0.82\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from lidaEnvironment import CompostingEnv\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Flatten the nested state into a single list of sensor values\n",
    "def flatten_state(state):\n",
    "    flat_state = []\n",
    "    for chamber_key in [\"active_chamber\", \"curing_chamber\"]:\n",
    "        chamber_data = state[chamber_key]\n",
    "        for sensor_key, values in chamber_data.items():\n",
    "            if isinstance(values, np.ndarray):\n",
    "                flat_state.extend(values.tolist())\n",
    "            else:\n",
    "                flat_state.append(float(values))\n",
    "    return flat_state\n",
    "\n",
    "# Encode and decode action for storage compatibility\n",
    "def encode_action(action):\n",
    "    active_chamber_action = action['active_chamber']\n",
    "    curing_chamber_action = action['curing_chamber']\n",
    "    return (\n",
    "        (active_chamber_action['paddle'][0], active_chamber_action['paddle'][1],\n",
    "         active_chamber_action['air_pump'], active_chamber_action['lid'], active_chamber_action['duration']),\n",
    "        (curing_chamber_action['paddle'][0], curing_chamber_action['paddle'][1],\n",
    "         curing_chamber_action['air_pump'], curing_chamber_action['lid'], curing_chamber_action['duration'])\n",
    "    )\n",
    "\n",
    "def decode_action(encoded_action):\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (encoded_action[0][0], encoded_action[0][1]),\n",
    "            \"air_pump\": encoded_action[0][2],\n",
    "            \"lid\": encoded_action[0][3],\n",
    "            \"duration\": encoded_action[0][4]\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (encoded_action[1][0], encoded_action[1][1]),\n",
    "            \"air_pump\": encoded_action[1][2],\n",
    "            \"lid\": encoded_action[1][3],\n",
    "            \"duration\": encoded_action[1][4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define RL parameters\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "\n",
    "# Initialize environment and determine state_dim from a flattened state sample\n",
    "env = CompostingEnv()\n",
    "sample_state = flatten_state(env.reset())  # Flattened sample state\n",
    "state_dim = len(sample_state)  # Get the length of the flattened state\n",
    "action_dim = 4  # Example with 4 possible actions; adjust as needed\n",
    "\n",
    "# Initialize DQN and optimizer with the correct input dimension\n",
    "policy_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net = DQN(input_dim=state_dim, output_dim=action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "# Generate random action compatible with the environment's dictionary action space\n",
    "def generate_random_action():\n",
    "    return {\n",
    "        \"active_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        },\n",
    "        \"curing_chamber\": {\n",
    "            \"paddle\": (random.randint(0, 1), random.randint(0, 1)),\n",
    "            \"air_pump\": random.randint(0, 1),\n",
    "            \"lid\": random.randint(0, 1),\n",
    "            \"duration\": random.randint(1, env.max_duration)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Choose action using epsilon-greedy strategy\n",
    "def choose_action(state, epsilon):\n",
    "    state_values = flatten_state(state)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        return generate_random_action()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state_values).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            action_index = q_values.max(1)[1].item()\n",
    "            return generate_random_action()  # Return random action for simplicity\n",
    "\n",
    "# Sample from replay buffer\n",
    "def sample_from_buffer(buffer, batch_size):\n",
    "    batch = random.sample(buffer, batch_size)\n",
    "    states, encoded_actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "    # Extract a scalar or index from the encoded actions for indexing Q-values\n",
    "    # Example: Using only the \"air_pump\" action as a scalar index for simplicity\n",
    "    actions = torch.LongTensor([action[0][2] for action in encoded_actions])  # Just an example\n",
    "\n",
    "    return (\n",
    "        torch.FloatTensor(states),\n",
    "        actions,\n",
    "        torch.FloatTensor(rewards),\n",
    "        torch.FloatTensor(next_states),\n",
    "        torch.FloatTensor(dones),\n",
    "    )\n",
    "\n",
    "\n",
    "# Update the Q network\n",
    "def update_model():\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    # Sample from replay buffer and extract components\n",
    "    states, actions, rewards, next_states, dones = sample_from_buffer(replay_buffer, BATCH_SIZE)\n",
    "    \n",
    "    # Get Q-values for the current policy network\n",
    "    q_values = policy_net(states)  # Output shape [BATCH_SIZE, action_dim]\n",
    "\n",
    "    # Use actions to gather specific Q-values from policy_net\n",
    "    q_values = q_values.gather(1, actions.view(-1, 1).long()).squeeze(1)  # Shape [BATCH_SIZE]\n",
    "    \n",
    "    # Calculate next Q-values from target network\n",
    "    next_q_values = target_net(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (GAMMA * next_q_values * (1 - dones))\n",
    "\n",
    "    # Compute loss and perform a backward pass\n",
    "    loss = nn.MSELoss()(q_values, expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store encoded action\n",
    "        replay_buffer.append((flatten_state(state), encode_action(action), reward, flatten_state(next_state), done))\n",
    "        state = next_state\n",
    "\n",
    "        update_model()\n",
    "\n",
    "    if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward:.2f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a5634-8a10-4c9d-9d51-3bee98c991d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
