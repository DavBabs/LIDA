{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0982fcb-fab0-4613-8a38-0535775dcc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install gym numpy stable-baselines3 matplotlib tensorflow keras keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c33e9b7-410c-48f2-924b-b058c179ea6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2319680f-0a32-4474-b6ab-363fcafb0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompostingEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(CompostingEnv, self).__init__()\n",
    "        \n",
    "        with open('optimal_conditions.json') as f:\n",
    "            self.optimal_conditions = json.load(f)\n",
    "        # Define structured observation space\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"temperature_active\": spaces.Box(low=0, high=100, shape=(4,), dtype=np.float32),\n",
    "            \"temperature_curing\": spaces.Box(low=0, high=100, shape=(2,), dtype=np.float32),\n",
    "            \"moisture_active\": spaces.Box(low=0, high=100, shape=(2,), dtype=np.float32),\n",
    "            \"moisture_curing\": spaces.Box(low=0, high=100, shape=(2,), dtype=np.float32),\n",
    "            \"gases\": spaces.Dict({\n",
    "                \"co2\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32),\n",
    "                \"oxygen\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32),\n",
    "                \"methane\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32)\n",
    "            }),\n",
    "        })\n",
    "        \n",
    "       # Define the action space with duration for motor and air pump actions\n",
    "        self.action_space = spaces.Dict({\n",
    "            \"motor\": spaces.Dict({\n",
    "                \"id\": spaces.Discrete(2),  # Motor ID: 0, 1\n",
    "                \"duration_ms\": spaces.Box(low=0, high=10000, shape=(1,), dtype=np.float32)\n",
    "            }),\n",
    "            \"actions\": spaces.Tuple([\n",
    "                spaces.Dict({\n",
    "                    \"type\": spaces.Discrete(1),  # Only 1 type here for air_pump\n",
    "                    \"id\": spaces.Discrete(2),  # Air pump ID: 0, 1\n",
    "                    \"duration_ms\": spaces.Box(low=0, high=10000, shape=(1,), dtype=np.float32)\n",
    "                }),\n",
    "                spaces.Dict({\n",
    "                    \"type\": spaces.Discrete(1),  # Only 1 type here for air_pump\n",
    "                    \"id\": spaces.Discrete(2),  # Air pump ID: 0, 1\n",
    "                    \"duration_ms\": spaces.Box(low=0, high=10000, shape=(1,), dtype=np.float32)\n",
    "                })\n",
    "            ])\n",
    "        })\n",
    "        \n",
    "         # Initialize state and any other necessary variables\n",
    "        self.state = self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = {\n",
    "            \"temperature_active\": np.array([50.0, 50.0, 50.0, 50.0], dtype=np.float32),\n",
    "            \"temperature_curing\": np.array([60.0, 60.0], dtype=np.float32),\n",
    "            \"moisture_active\": np.array([60.0, 60.0], dtype=np.float32),\n",
    "            \"moisture_curing\": np.array([70.0, 70.0], dtype=np.float32),\n",
    "            \"gases\": {\n",
    "                \"co2\": np.array([5.0], dtype=np.float32),\n",
    "                \"oxygen\": np.array([15.0], dtype=np.float32),\n",
    "                \"methane\": np.array([1.0], dtype=np.float32)\n",
    "            }\n",
    "        }\n",
    "        return self.state\n",
    "\n",
    "\n",
    "    def calculate_reward_points(current, minvalue, maxvalue):\n",
    "    # If the current value is less than the minimum, calculate reward as current / active_min\n",
    "    if (current / minvalue) < 1:\n",
    "        return (current / minvalue)\n",
    "    # If the current value is within the optimal range, return full reward (1)\n",
    "    elif (current >= minvalue and current <= maxvalue):\n",
    "        return 1\n",
    "    # If the current value is greater than the maximum, scale the reward as active_max / current\n",
    "    elif (current / maxvalue) > 1:\n",
    "        return (maxvalue / current)\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "    # Define the stages of the composting process\n",
    "    stages = ['initial', 'mid', 'final']\n",
    "    current_stage = stages[0]  # Example: This would change dynamically based on progress\n",
    "\n",
    "    # Retrieve the current environmental state values\n",
    "    temperature = np.mean(self.state['temperature_active'])\n",
    "    moisture = np.mean(self.state['moisture_active'])\n",
    "    co2 = self.state['gases']['co2']\n",
    "    methane = self.state['gases']['methane']\n",
    "    o2 = self.state['gasses']['oxygen']\n",
    "\n",
    "    # Use the updated calculate_reward() function to compute the reward for each variable\n",
    "    temp_reward = calculate_reward_points(temperature, optimal.active_min, optimal.active_max)\n",
    "    ch4 = calculate_reward_points(methane, optimal.moisture_min, optimal.moisture_max)\n",
    "    co2_reward = calculate_reward_points(co2, optimal.co2_min, optimal.co2_max)\n",
    "    o2_reward = calculate_reward_points(o2, optimal.o2_min, optimal.o2_max)\n",
    "    \n",
    "    temp_weight = 0.4\n",
    "    ch4_weight = 0.3\n",
    "    o2_weight = 0.2\n",
    "    co2_weight = 0.1\n",
    "    \n",
    "\n",
    "    # The total reward is the average of the rewards for all variables\n",
    "    total_reward = (\n",
    "        temp_reward * temp_weight + \n",
    "        ch4_reward * ch4_weight + \n",
    "        o2_reward * o2_weight + \n",
    "        co2_reward * co2_weight)\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute an action, update the state, calculate reward, and return the results\n",
    "        \"\"\"\n",
    "        # 1. Apply action: this can define how motors and air pumps affect temperature and humidity\n",
    "        self._apply_action(action)\n",
    "\n",
    "        # 2. Update state: update temperature, humidity, and gas concentrations\n",
    "        self._update_state()\n",
    "\n",
    "        # 3. Calculate the reward\n",
    "        reward = self.calculate_reward()\n",
    "\n",
    "        # 4. Check if the episode is finished\n",
    "        done = self._check_done()\n",
    "\n",
    "        # 5. Return the new state, reward, completion status, and any debug information\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        \"\"\"\n",
    "        Apply the input action to update the motor or air pump control parameters\n",
    "        \"\"\"\n",
    "        motor_action = action['motor']\n",
    "        pump_action = action['actions']\n",
    "        \n",
    "        # Dynamically adjust action timing based on optimal conditions\n",
    "        motor_duration = self._get_dynamic_duration(np.mean(self.state['temperature_active']), 'temperature', 'active')\n",
    "        motor_action['duration_ms'][0] = motor_duration\n",
    "\n",
    "        # Adjust air pump action duration based on optimal gas levels\n",
    "        for pump in pump_action:\n",
    "            pump_duration = self._get_dynamic_duration(self.state['gases']['co2'][0], 'gases', 'co2')\n",
    "            pump['duration_ms'][0] = pump_duration\n",
    "\n",
    "        # Assume longer air pump run time reduces CO2 and methane, increases oxygen\n",
    "        co2_reduction = pump_duration * 0.01\n",
    "        methane_reduction = pump_duration * 0.005\n",
    "        oxygen_increase = pump_duration * 0.015\n",
    "\n",
    "        self.state['gases']['co2'][0] = max(0, self.state['gases']['co2'][0] - co2_reduction)\n",
    "        self.state['gases']['methane'][0] = max(0, self.state['gases']['methane'][0] - methane_reduction)\n",
    "        self.state['gases']['oxygen'][0] = min(100, self.state['gases']['oxygen'][0] + oxygen_increase)\n",
    "\n",
    "     def _get_dynamic_duration(self, current_value, category, variable):\n",
    "        \"\"\"\n",
    "        Get dynamic action duration based on the current state and optimal conditions\n",
    "        \"\"\"\n",
    "        optimal_min = self.optimal_conditions[category][variable]['min']\n",
    "        optimal_max = self.optimal_conditions[category][variable]['max']\n",
    "\n",
    "        # Calculate duration as a function of deviation from optimal conditions\n",
    "        if current_value < optimal_min:\n",
    "            duration = (optimal_min - current_value) * 100  # Example scaling factor\n",
    "        elif current_value > optimal_max:\n",
    "            duration = (current_value - optimal_max) * 100\n",
    "        else:\n",
    "            duration = 500  # Default duration if within optimal range\n",
    "\n",
    "        return np.clip(duration, 0, 10000)  # Ensure duration stays within valid range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253782a-8e36-40a9-a3b6-6ce8259fa982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CapstoneML",
   "language": "python",
   "name": "capstoneml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
